var store = [{
        "title": "우분투(Ubuntu) 환경에 패키지로 OpenJDK(Java) 설치하기",
        "excerpt":"OpenJDK는 Java 애플리케이션 구축을 위한 오픈 소스 기반의 JDK(Java Development Kit)입니다.   JDK는 JVM(Java Virtual Machine), JRE(Java Runtime Environment)와 함께 Java 프로그래밍에 필요한 핵심 기술 패키지입니다.   JDK는 2개로 나뉘는데, 하나는 BCL(Oracle Binary Code License) 라이선스의 Oracle JDK, 하나는 GNU GPL v2(GNU General Public License) 라이선스의 OpenJDK입니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 패키지로 OpenJDK를 설치하는 방법을 소개합니다.      Oracle JDK와 OpenJDK에 대한 자세한 정보는 Oracle JDK와 OpenJDK의 차이점 포스트를 참고하시기 바랍니다.    선행조건(PREREQUISITE)     Ubuntu 환경이 필요합니다.      Ubuntu 설치 방법은 VMware workstation에 Ubuntu 16.04 설치하기 또는 VMware workstation에 Ubuntu 18.04 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 16.04.4 LTS (Xenial Xerus) Server (64-bit)   OpenJDK 1.8.0_222   요약(SUMMARY)     apt 명령어로 OpenJDK 설치   OpenJDK 설치 확인   Ubuntu 환경변수에 OpenJDK Java 경로 설정   (선택사항) apt 명령어로 OpenJDK 삭제   내용(CONTENTS)  1. apt 명령어로 OpenJDK 설치  $ sudo apt update -y &amp;&amp; sudo apt install openjdk-8-jdk -y   2. OpenJDK 설치 확인  $ java -version openjdk version \"1.8.0_222\" OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10) OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)   3. Ubuntu 환경변수에 OpenJDK Java 경로 설정  3.1. 설치된 Java 경로 확인  $ which java /usr/bin/java   3.2. OpenJDK Java 경로 추가     루트(root) 계정    $ sudo vi /etc/profile 또는 # vi $HOME/.bashrc      일반 계정    $ vi $HOME/.profile      root 계정으로 OpenJDK Java 경로를 추가합니다.   $ sudo vi /etc/profile   ---------------------------------------------------------------------------------------------------- JAVA_HOME=$(dirname $(dirname $(update-alternatives --list javac))) JAVA=${JAVA_HOME}/bin CLASSPATH=.:${JAVA_HOME}/lib/tools.jar PATH=${PATH}:${JAVA}  export JAVA_HOME JAVA CLASSPATH PATH ----------------------------------------------------------------------------------------------------      수정 내역 적용을 위해 아래 명령어를 입력합니다.    $ source /etc/profile   4. (선택사항) apt 명령어로 OpenJDK 삭제     ’–auto-remove’ 옵션을 추가하면, 사용하지 않는 관련 패키지를 모두 삭제합니다.   4.1. apt remove 명령어로 OpenJDK 삭제     설정 파일을 유지하며 OpenJDK를 삭제합니다.   $ sudo apt remove openjdk* $ sudo apt remove --auto-remove openjdk*   4.2. apt purge 명령어로 OpenJDK 삭제     설정 파일과 함께 OpenJDK를 삭제합니다. (단, 사용자 홈 디렉터리의 설정 파일은 유지됩니다.)   $ sudo apt purge openjdk* $ sudo apt purge --auto-remove openjdk*   마무리(CONCLUSION)  Ubuntu 환경에 패키지로 OpenJDK 설치를 완료했습니다.   JDK는 Java 프로그래밍에 필수 요소이며, 상당수의 오픈소스 소프트웨어와 국내 SI(System Integration) 프로젝트에서 JDK를 요구합니다.   정부 발주 프로젝트에 다수를 차지하는 SI 회사가 Java + 스프링 프레임워크(Spring Framework) 또는 Java + 전자정부표준프레임워크(약칭 eGov) 구성을 사용하기 때문에 Java의 인기는 시들지 않고 있습니다.   Java는 플랫폼에 독립적이고 수많은 개발자와 레퍼런스를 보유하고 있다는 장점과 속도 문제라는 단점을 가진 언어입니다.   국내 현업에서는 Java를 비롯한 여러 가지 언어가 자주 사용되므로 개발 환경이나 작업 특성에 따라 적합한 언어를 선택할 수 있는 지식과 노하우가 필요합니다.   참고(REFERENCES)     https://openjdk.java.net/   https://ko.wikipedia.org/wiki/OpenJDK   https://namu.wiki/w/Java  ","categories": ["ubuntu"],
        "tags": ["openjdk","java","ubuntu"],
        "url": "https://lindarex.github.io/ubuntu/ubuntu-openjdk-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "Oracle JDK와 OpenJDK의 차이점",
        "excerpt":"Java 애플리케이션 구축을 위해서는 JDK(Java Development Kit)가 필수입니다.   이 포스트에서는 Oracle JDK와 OpenJDK의 차이점을 간단히 소개합니다.   내용(CONTENTS)  Oracle JDK와 OpenJDK의 차이점     Oracle JDK는 상용(유료)이지만, OpenJDK는 오픈소스기반(무료)입니다.   Oracle JDK의 라이선스는 Oracle BCL(Binary Code License) Agreement이지만, OpenJDK의 라이선스는 Oracle GPL v2입니다.   Oracle JDK는 LTS(장기 지원) 업데이트 지원을 받을 수 있지만, OpenJDK는 LTS 없이 6개월마다 새로운 버전이 배포됩니다.   Oracle JDK는 Oracle이 인수한 Sun Microsystems 플러그인을 제공하지만, OpenJDK는 제공하지 않습니다.   Oracle JDK는 OpenJDK 보다 CPU 사용량과 메모리 사용량이 적고, 응답시간이 높습니다.      Oracle JDK와 OpenJDK의 벤치마킹 결과는 Comparing JDK 8 performance 페이지를 참고하시기 바랍니다.    마무리(CONCLUSION)  Oracle은 2019년 1월부터 Java를 상용으로 사용하거나 지속적인 업데이트를 받으려는 기업 사용자에게 유료로 제공하고 있으며,  현재 2020년 2월 기준으로 Oracle JDK 8은 개인 또는 개발 용도의 사용은 무료지만, 2021년부터는 유료화로 전환될 것으로 알려져 있습니다.   JDK 유료화에 따라 개인 사용자를 비롯해 기업 사용자는 OpenJDK를 적용하기 위해 호환성, 안정성, 성능 등의 검증이 필요합니다. 또한, 배포 버전에 따른 생산성 확인과 보안 이슈 등을 충분히 인지하고 테스트할 필요가 있습니다.   더 자세한 내용은 아래 참고 페이지를 확인해 주시기 바랍니다.   참고(REFERENCES)     https://engineering.linecorp.com/ko/blog/line-open-jdk/   https://c10106.tistory.com/4075   https://jsonobject.tistory.com/395   ","categories": ["concepts"],
        "tags": ["oraclejdk","openjdk","java"],
        "url": "https://lindarex.github.io/concepts/difference-between-oraclejdk-openjdk/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 방화벽(Firewalld) 설치 및 설정하기",
        "excerpt":"방화벽(이하 firewalld)은 IPv4, IPv6, 이더넷 브리지 및 IPSet의 방화벽 설정을 지원하는 리눅스(이하 linux) 방화벽 관리 도구입니다.   firewalld는 linux 커널 netfilter 프레임워크의 프런트 엔드 역할을 하며, RHEL 7 제품군의 기본 방화벽 관리 소프트웨어입니다.   우분투(이하 Ubuntu)의 기본 방화벽 시스템은 UFW(Uncomplicated Firewall)이지만, firewalld를 설치하고 사용할 수 있습니다.   이 포스트에서는 Ubuntu 환경에서 패키지로 firewalld를 설치하고 설정하는 방법을 소개합니다.      UFW 설정 방법은 우분투(Ubuntu) 환경에 방화벽(UFW) 설정하기 포스트를 참고하시기 바랍니다.    선행조건(PREREQUISITE)     Ubuntu 환경이 필요합니다.      Ubuntu 설치 방법은 VMware workstation에 Ubuntu 16.04 설치하기 또는 VMware workstation에 Ubuntu 18.04 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 16.04.4 LTS (Xenial Xerus) Server (64-bit)   요약(SUMMARY)     apt 명령어로 firewalld 설치   firewalld 설치 확인   firewalld 설정   내용(CONTENTS)  1. apt 명령어로 firewalld 설치  $ sudo apt update -y &amp;&amp; sudo apt install firewalld -y   2. firewalld 설치 확인  $ sudo firewall-cmd --version 0.4.4.5   3. firewalld 설정  3.1. firewalld에  rule 추가     아래 예제는 영구적으로 public zone에 TCP 8080 포트를 추가하는 명령어입니다.    $ sudo firewall-cmd --permanent --zone=public --add-port=8080/tcp   3.2. firewalld에 rule 적용     아래 명령어를 실행하기 전에는 추가한 rule이 적용되지 않습니다.    $ sudo firewall-cmd --reload   3.3. firewalld에 설정된 모든 값 조회  $ sudo firewall-cmd --list-all public   target: default   icmp-block-inversion: no   interfaces:   sources:   services: ssh dhcpv6-client   ports: 8080/tcp   protocols:   masquerade: no   forward-ports:   source-ports:   icmp-blocks:   rich rules:   마무리(CONCLUSION)  Ubuntu 환경에 패키지로 firewalld 설치 및 설정을 완료했습니다.   firewalld는 CentOS 7부터 이전의 Iptables를 대체해 새롭게 선보인 패킷 필터링 방화벽 프로그램입니다.   다음 포스트에서는 Iptables, UFW 등의 방화벽 특징과 설정 방법을 소개하겠습니다.   참고(REFERENCES)     http://manpages.ubuntu.com/manpages/bionic/man1/firewall-cmd.1.html   https://computingforgeeks.com/install-and-use-firewalld-on-ubuntu-18-04-ubuntu-16-04/  ","categories": ["ubuntu"],
        "tags": ["firewalld","ubuntu"],
        "url": "https://lindarex.github.io/ubuntu/ubuntu-firewalld-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 16.04 설치하기",
        "excerpt":"우분투(Ubuntu)는 데비안(이하 debian) 리눅스(이하 linux) 기반으로, debian에 비해 사용자 편의성에 초점을 맞춘 linux 배포판이며 컴퓨터 운영체제(OS, Operating System)입니다.   새로운 버전은 6개월마다, 장기 지원 버전(LTS, Long Term Support)은 2년에 한 번씩 출시되고, 다양한 언어를 지원하고 낮은 사양의 컴퓨터에서도 작동하도록 설계되어 있습니다.   이 포스트에서는 VMware Workstation에 Ubuntu 16.04를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     VMware Workstation이 설치되어 있어야 합니다.   테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 16.04.6 LTS (Xenial Xerus) Server (64-bit)      Ubuntu 16.04 Server 설치 시 필요한 시스템 요구사항은 https://help.ubuntu.com/16.04/serverguide/preparing-to-install.html를 확인해 주시기 바랍니다.    요약(SUMMARY)     Ubuntu 16.04.6 Server ISO 파일 내려받기   VMware workstation의 VM(Virtual Machine) 설정   Ubuntu 16.04 설치   리눅스 명령어로 Ubuntu VM 상태 확인   내용(CONTENTS)  1. Ubuntu 16.04.6 Server ISO 파일 내려받기     웹브라우저로 Ubuntu Releases 페이지를 엽니다.         목록의 ‘16.04.6’를 클릭하여 Ubuntu 16.04.6 LTS (Xenial Xerus) 페이지로 이동합니다.         Server install image 영역의 ‘64-bit PC (AMD64) server install image’를 클릭하여 ISO 파일을 내려받습니다.      http://mirror.kakao.com/ubuntu-releases/16.04.6/ubuntu-16.04.6-server-amd64.iso를 통해 바로 내려받을 수 있습니다.   ubuntu-16.04.6-server-amd64.iso 파일 사이즈는 약 893 MB입니다.       2. VMware workstation의 VM(Virtual Machine) 설정     VMware workstation을 실행합니다.   아래 메뉴를 통해 ‘New Virtual Machine Wizard’ 팝업을 엽니다.      상단 메뉴 &gt; File &gt; ‘New Virtual Machine…’ 또는 Ctrl + N          상세 설정을 위해 ‘Custom (advanced)’를 선택하고 ‘Next’를 클릭합니다.         VMware Workstation 버전을 선택하고 ‘Next’를 클릭합니다.         상세 설정을 위해 ‘I will install the operating system later.’를 선택하고 ‘Next’를 클릭합니다.         Guest operating system은 ‘Linux’, Version은 ‘Ubuntu 64-bit’를 선택하고 ‘Next’를 클릭합니다.         Virtual machine name을 입력하고, Location에 vmdk 파일이 저장될 경로를 입력하거나 ‘Browse..’를 클릭해 위치를 선택하고 ‘Next’를 클릭합니다.      VMDK란 Virtual Machine Disk의 약자이며, 자세한 정보는 https://en.wikipedia.org/wiki/VMDK를 참고하시기 바랍니다.          processors ‘1’, cores per processor ‘1’을 입력하고 ‘Next’를 클릭합니다.         권장값인 ‘2048’MB를 입력하고 ‘Next’를 클릭합니다.      권장값은 자신의 PC 메모리(Host memory)에 따라 다를 수 있습니다.          ‘Use network address translation (NAT)’를 선택하고 ‘Next’를 클릭합니다.      Network type에 대한 자세한 정보는 VMware Workstation의 가상 네트워크(Virtual Network) 알아보기 포스트를 참고하시기 바랍니다.          권장값인 ‘LSI Logic (Recommended)’를 선택하고 ‘Next’를 클릭합니다.         권장값인 ‘SCSI Logic (Recommended)’를 선택하고 ‘Next’를 클릭합니다.         ‘Create a new virtual disk’를 선택하고 ‘Next’를 클릭합니다.         Maximum disk size를 ‘20.0’을 입력하고 ‘Split virtual disk into multiple files’를 선택하고 ‘Next’를 클릭합니다.         Disk file 명을 입력하고 ‘Next’를 클릭합니다.         ‘Customize Hardware..’를 클릭하여 Hardware 팝업을 엽니다.         앞에서 설정한 내용을 확인합니다. (Memory, Processors)            Use ISO image file 항목의 ‘Browse..’를 클릭해 내려받은 Ubuntu 16.04.6 LTS (Xenial Xerus) ISO 파일을 선택합니다.         앞에서 설정한 내용을 확인합니다. (Network Adapter, USB Controller, Sound Card, Printer, Display)                     모든 설정을 확인하고 ‘Finish’를 클릭합니다.      3. Ubuntu 16.04 설치     아래 메뉴를 통해 Ubuntu VM을 구동합니다.      상단 메뉴 &gt; 녹색 플레이 버튼 또는 Ctrl + B          설치할 때 사용하고자 하는 언어를 선택합니다.         ‘Install Ubuntu Server’를 선택하여 설치를 시작합니다.         Ubuntu Server에 사용하고자 하는 언어를 설정합니다. ‘English’를 선택합니다.         Location을 설정합니다. ‘other’를 선택한 후, ‘Asia’의 ‘Korea, Republic of’를 선택합니다.               Locale을 설정합니다. ‘United States’를 선택합니다.         Keyboard layout을 설정합니다. ‘No’를 선택한 후, ‘English (US)’를 선택합니다.               설치가 진행됩니다.         호스트네임(Hostname)을 입력합니다.         사용자 이름(User name)을 입력합니다.            비밀번호(Password)를 입력합니다.            Home directory의 암호화를 설정합니다. ‘No’를 선택합니다.         설치가 진행됩니다.         타임존(Time zone)을 설정합니다.         Disk partition을 설정합니다. ‘Guided - use entire disk and set up LVM’을 선택합니다.                     설치가 진행됩니다.         HTTP proxy를 설정합니다.         설치가 진행됩니다.         Upgrade 주기를 설정합니다.         추가로 설치할 패키지를 선택합니다.      Xshell을 비롯해 SSH 클라이언트 사용을 위해 OpenSSH server 패키지를 추가합니다.          설치가 진행됩니다.         GRUB boot loader를 설정합니다. ‘Yes’를 선택합니다.         설치가 진행됩니다.         설치 과정의 마지막입니다. ‘Continue’를 선택합니다.         재부팅됩니다.         정상 설치 후 로그인 프롬프트 상태입니다.      4. 리눅스 명령어로 Ubuntu VM 상태 확인      사용자 이름과 비밀번호를 입력하여 로그인합니다.         free 명령어로 메모리 상태를 확인합니다.         df 명령어로 디스크 사용량을 확인합니다.         ifconfig 명령어로 네트워크 정보를 확인합니다.         ping 명령어로 네트워크 상태를 확인합니다.         apt update 명령어로 패키지 인덱스를 업데이트합니다.      apt update 명령어는 업그레이드 가능한 패키지 정보를 업데이트하는 것이며, 실제로 패키지를 업데이트하지 않습니다.          apt upgrade 명령어로 업그레이드 가능한 모든 패키지를 업데이트합니다.            마무리(CONCLUSION)  VMware Workstation에 Ubuntu 16.04.6 LTS (Xenial Xerus) Server 설치를 완료했습니다.   2020년 2월 12일 W3Techs.com 통계에 따르면, Ubuntu 점유율은 linux 배포판을 사용하는 웹사이트 중 1위(38.9%)로, 2위인 debian(18.4%)의 2배 이상 차이가 납니다. 또한 대부분의 오픈소스 소프트웨어는 Ubuntu를 지원하고, 국내외 사용자와 레퍼런스가 많습니다.   리눅스 입문자 또는 오픈소스 소프트웨어에 관심이 있다면, Ubuntu를 사용하며 리눅스 명령어를 숙지하고 다양한 커뮤니티에서 활동하는 것을 권합니다.   참고(REFERENCES)     https://ubuntu.com/   http://mirror.kakao.com/ubuntu-releases/   https://ubuntu.com/tutorials/tutorial-install-ubuntu-server#1-overview   https://ko.wikipedia.org/wiki/우분투_(운영_체제)   ","categories": ["ubuntu"],
        "tags": ["ubuntu","16.04","vmware workstation"],
        "url": "https://lindarex.github.io/ubuntu/ubuntu-1604-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 18.04 설치하기",
        "excerpt":"우분투(Ubuntu) 18.04 LTS(Long Term Support)는 Ubuntu 16.04 LTS와 비교해 새로운 기능과 개선 사항으로 많은 변화가 있으며, 릴리스의 코드 이름은 ‘Bionic Beaver’입니다.   이 포스트에서는 VMware Workstation에 Ubuntu 18.04 LTS를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     VMware Workstation이 설치되어 있어야 합니다.   테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)      Ubuntu 18.04 Server 설치 시 필요한 시스템 요구사항은 https://help.ubuntu.com/lts/serverguide/preparing-to-install.html를 확인해 주시기 바랍니다.    요약(SUMMARY)     Ubuntu 18.04.3 Server ISO 파일 내려받기   VMware workstation의 VM(Virtual Machine) 설정   Ubuntu 18.04 설치   리눅스 명령어로 Ubuntu VM 상태 확인   내용(CONTENTS)  1. Ubuntu 18.04.3 Server ISO 파일 내려받기     웹브라우저로 Ubuntu Releases 페이지를 엽니다.         목록의 ‘18.04.3’을 클릭하여 Ubuntu 18.04.3 LTS (Bionic Beaver) 페이지로 이동합니다.         Server install image 영역의 ‘64-bit PC (AMD64) server install image’를 클릭하여 ISO 파일을 내려받습니다.      http://mirror.kakao.com/ubuntu-releases/18.04.3/ubuntu-18.04.3-live-server-amd64.iso를 통해 바로 내려받을 수 있습니다.   ubuntu-18.04.3-live-server-amd64.iso 파일 사이즈는 약 868 MB입니다.       2. VMware workstation의 VM(Virtual Machine) 설정     VMware workstation을 실행합니다.   아래 메뉴를 통해 ‘New Virtual Machine Wizard’ 팝업을 엽니다.      상단 메뉴 &gt; File &gt; ‘New Virtual Machine…’ 또는 Ctrl + N          상세 설정을 위해 ‘Custom (advanced)’를 선택하고 ‘Next’를 클릭합니다.         VMware Workstation 버전을 선택하고 ‘Next’를 클릭합니다.         상세 설정을 위해 ‘I will install the operating system later.’를 선택하고 ‘Next’를 클릭합니다.         Guest operating system은 ‘Linux’, Version은 ‘Ubuntu 64-bit’를 선택하고 ‘Next’를 클릭합니다.         Virtual machine name을 입력하고, Location에 vmdk 파일이 저장될 경로를 입력하거나 ‘Browse..’를 클릭해 위치를 선택하고 ‘Next’를 클릭합니다.      VMDK란 Virtual Machine Disk의 약자이며, 자세한 정보는 https://en.wikipedia.org/wiki/VMDK를 참고하시기 바랍니다.          processors ‘1’, cores per processor ‘1’을 입력하고 ‘Next’를 클릭합니다.         권장값인 ‘2048’MB를 입력하고 ‘Next’를 클릭합니다.      권장값은 자신의 PC 메모리(Host memory)에 따라 다를 수 있습니다.          ‘Use network address translation (NAT)’를 선택하고 ‘Next’를 클릭합니다.      Network type에 대한 자세한 정보는 VMware Workstation의 가상 네트워크(Virtual Network) 알아보기 포스트를 참고하시기 바랍니다.          권장값인 ‘LSI Logic (Recommended)’를 선택하고 ‘Next’를 클릭합니다.         권장값인 ‘SCSI Logic (Recommended)’를 선택하고 ‘Next’를 클릭합니다.         ‘Create a new virtual disk’를 선택하고 ‘Next’를 클릭합니다.         Maximum disk size를 ‘20.0’을 입력하고 ‘Split virtual disk into multiple files’를 선택하고 ‘Next’를 클릭합니다.         Disk file 명을 입력하고 ‘Next’를 클릭합니다.         ‘Customize Hardware..’를 클릭하여 Hardware 팝업을 엽니다.         앞에서 설정한 내용을 확인합니다. (Memory, Processors)            Use ISO image file 항목의 ‘Browse..’를 클릭해 내려받은 Ubuntu 18.04.3 LTS (Bionic Beaver) ISO 파일을 선택합니다.         앞에서 설정한 내용을 확인합니다. (Network Adapter, USB Controller, Sound Card, Printer, Display)                     모든 설정을 확인하고 ‘Finish’를 클릭합니다.      3. Ubuntu 18.04 설치     아래 메뉴를 통해 Ubuntu VM을 구동합니다.      상단 메뉴 &gt; 녹색 플레이 버튼 또는 Ctrl + B          설치가 진행됩니다.         사용하고자 하는 언어를 선택합니다.         Keyboard layout을 설정합니다. ‘English (US)’를 선택합니다.         Network를 설정합니다.      VMware Workstation에 Ubuntu를 설치할 경우, 자동으로 DHCP(Dynamic Host Configuration Protocol)로 설정됩니다.   DHCP에 대한 자세한 정보는 https://ko.wikipedia.org/wiki/동적_호스트_구성_프로토콜를 참고하시기 바랍니다.          Proxy를 설정합니다.         Ubuntu archive mirror address를 설정합니다.         Filesystem을 설정합니다. ‘Use An Entire Disk and Set Up LVM’을 선택합니다.                  사용자 프로필을 설정합니다.         SSH 설치 여부를 선택합니다.      Xshell을 비롯해 SSH 클라이언트 사용을 위해 OpenSSH server 패키지를 설치합니다.          추가로 설치할 패키지를 선택합니다.         설치가 진행됩니다.            설치가 완료되었습니다. ‘Reboot’를 선택합니다.         재부팅됩니다.         정상 설치 후 로그인 프롬프트 상태입니다.      4. 리눅스 명령어로 Ubuntu VM 상태 확인      사용자 이름과 비밀번호를 입력하여 로그인합니다.         free 명령어로 메모리 상태를 확인합니다.         df 명령어로 디스크 사용량을 확인합니다.         ifconfig 명령어로 네트워크 정보를 확인합니다.         ping 명령어로 네트워크 상태를 확인합니다.         apt update 명령어로 패키지 인덱스를 업데이트합니다.      apt update 명령어는 업그레이드 가능한 패키지 정보를 업데이트하는 것이며, 실제로 패키지를 업데이트하지 않습니다.          apt upgrade 명령어로 업그레이드 가능한 모든 패키지를 업데이트합니다.         마무리(CONCLUSION)  VMware Workstation에 Ubuntu 18.04.3 LTS (Bionic Beaver) Server 설치를 완료했습니다.   다음 포스트에서는 Ubuntu Server 운영 시 유용한 패키지를 소개하겠습니다.   참고(REFERENCES)     https://ubuntu.com/   http://mirror.kakao.com/ubuntu-releases/   https://ubuntu.com/tutorials/tutorial-install-ubuntu-server#1-overview   https://ko.wikipedia.org/wiki/우분투_(운영_체제)   ","categories": ["ubuntu"],
        "tags": ["ubuntu","18.04","vmware workstation"],
        "url": "https://lindarex.github.io/ubuntu/ubuntu-1804-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "VMware Workstation의 가상 네트워크(Virtual Network) 알아보기",
        "excerpt":"VMware Workstation은 가상 머신(Virtual Machine, 이하 VM)을 생성하고 가상 네트워크(Virtual Network)를 구성할 수 있습니다.   이 포스트에서는 VMware Workstation의 Virtual Network에 대해 소개합니다.   선행조건(PREREQUISITE)     VMware Workstation이 설치되어 있어야 합니다.   테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   요약(SUMMARY)     Bridged Networking   NAT Networking   Host-Only Networking      내용(CONTENTS)  1. Bridged Networking     Bridged Networking은 호스트(Host) 시스템의 네트워크 어댑터를 사용하여 VM을 Network에 연결합니다.   Bridged Networking을 적용한 VM은 물리적 시스템으로 인식되고, 공유기는 개별적으로 IP를 할당합니다.   공유기를 통해 외부 통신을 합니다.   동일한 네트워크에 있다는 전제하에, Bridged Networking을 적용한 VM은 Host 시스템을 비롯해 동일 네트워크 내의 다른 시스템에도 엑세스가 가능합니다.   VMware Workstation 설치 시 Bridged Network(VMnet0)가 설정됩니다.         출처 :: https://docs.vmware.com/en/VMware-Workstation-Player-for-Windows/15.0/com.vmware.player.win.using.doc/GUID-BAFA66C3-81F0-4FCA-84C4-D9F7D258A60A.html    2. NAT Networking     NAT(Network Address Translation) Networking을 적용한 VM은 외부 네트워크 통신을 위한 IP를 할당받지 않습니다.   Host 시스템에 별도의 개인 Network가 설정되고, NAT Networking을 적용한 VM은 가상 DHCP 서버로부터 내부 Network 대역을 할당받습니다.   Host 시스템을 통해 외부 통신을 합니다.   NAT Network는 하나만 존재합니다.   VMware Workstation 설치 시 NAT Network(VMnet8)가 설정됩니다.         출처 :: https://docs.vmware.com/en/VMware-Workstation-Player-for-Windows/15.0/com.vmware.player.win.using.doc/GUID-89311E3D-CCA9-4ECC-AF5C-C52BE6A89A95.html    3. Host-Only Networking     Host-Only Networking을 적용한 VM은 기본적으로 외부 통신, Host 시스템과 통신이 불가능합니다.   Host-Only Networking을 적용한 VM은 VMware Workstation에서 생성한 VM만 통신이 가능합니다.   VMware Workstation 설치 시 Host-Only Network(VMnet1)가 설정됩니다.         출처 :: https://docs.vmware.com/en/VMware-Workstation-Player-for-Windows/15.0/com.vmware.player.win.using.doc/GUID-93BDF7F1-D2E4-42CE-80EA-4E305337D2FC.html    마무리(CONCLUSION)  VMware Workstation의 Virtual Network에 대해 알아봤습니다.   다음 포스트에서는 VMware Workstation의 Virtual Network를 설정하는 방법을 소개하겠습니다.   참고(REFERENCES)     https://docs.vmware.com/en/VMware-Workstation-Player-for-Windows/15.0/com.vmware.player.win.using.doc/GUID-D9B0A52D-38A2-45D7-A9EB-987ACE77F93C.html   ","categories": ["vmware-workstation"],
        "tags": ["vmware workstation","virtual network","bridged","nat","host-only"],
        "url": "https://lindarex.github.io/vmware-workstation/vmware-workstation-virtual-network/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 패키지로 젠킨스(Jenkins) 설치하기",
        "excerpt":"젠킨스(이하 Jenkins)는 MIT license로 오픈소스 소프트웨어이며, 소프트웨어 개발 시 지속적 통합(CI, Continuous Integration) 서비스를 제공하는 자동화 서버입니다.   Jenkins는 모든 프로젝트의 빌드와 배포, 자동화를 지원하며, 수백 개의 플러그인을 제공합니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 패키지로 Jenkins를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경에 Java가 설치되어 있어야 합니다.            Jenkins 버전에 따른 필요 Java 버전                    2.164 (2019-02) and newer: Java 8 or Java 11           2.54 (2017-04) and newer: Java 8           1.612 (2015-05) and newer: Java 7                           방화벽 설정이 필요합니다.            TCP 8080 포트가 개방되어 있어야 합니다.              Java 설치 방법은 우분투(Ubuntu) 환경에 OpenJDK(Java) 설치하기 포스트를 참고하시기 바랍니다.       Java 버전에 대한 자세한 정보는 https://jenkins.io/doc/administration/requirements/java/를 확인해 주시기 바랍니다.       방화벽 설정 방법은 우분투(Ubuntu) 환경에 방화벽(Firewalld) 설치 및 설정하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 16.04.4 LTS (Xenial Xerus) Server (64-bit)   Jenkins 2.121.1   OpenJDK 1.8.0_171   요약(SUMMARY)     Jenkins debian packages repository 설정   apt 명령어로 Jenkins 설치   (선택사항) Java 경로 설정 및 Jenkins의 기본 포트 변경   systemctl 명령어로 Jenkins 실행   웹브라우저로 Jenkins 접속   내용(CONTENTS)  1. Jenkins debian packages repository key 추가  $ sudo wget -q -O - https://pkg.jenkins.io/debian/jenkins-ci.org.key | sudo apt-key add -   2. Jenkins debian packages repository 추가  $ sudo sh -c 'echo deb https://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'     3. apt install 명령어로 Jenkins 설치  $ sudo apt update -y &amp;&amp; sudo apt install jenkins -y     4. (선택사항) Java 경로 설정  4.1. 설치된 Java 경로 확인  $ sudo which java /usr/bin/java   4.2. Java 경로 추가  $ sudo vi /etc/init.d/jenkins   -------------------------------------------------------------------------------- PATH=\"/bin:/usr/bin:/sbin:/usr/sbin:/usr/bin/java\"  --------------------------------------------------------------------------------   5. (선택사항) 기본 포트 변경  $ sudo vi /etc/default/jenkins     -------------------------------------------------------------------------------- JENKINS_PORT=\"8080\"   JENKINS_AJP_PORT=\"9091\"   JENKINS_USER=\"root\"   --------------------------------------------------------------------------------   6. systemctl 명령어로 Jenkins 서비스 관리  6.1. Jenkins 서비스 설정 반영  $ sudo systemctl daemon-reload   6.2. Jenkins 서비스 시작  $ sudo systemctl start jenkins.service   6.3. Jenkins 서비스 중지  $ sudo systemctl stop jenkins.service   6.4. Jenkins 서비스 재시작  $ sudo systemctl restart jenkins.service   6.5. Jenkins 서비스 설정 재적용  $ sudo systemctl reload jenkins.service   6.6. Jenkins 서비스 상태 조회  $ sudo systemctl status jenkins.service   6.7. Jenkins 서비스 활성화(부팅 시 자동 시작)  $ sudo systemctl enable jenkins.service   6.8. Jenkins 서비스 비활성화  $ sudo systemctl disable jenkins.service   6.9. Jenkins 서비스 및 관련 프로세스 모두 중지  $ sudo systemctl kill jenkins.service   7. 웹브라우저로 Jenkins 접속     http://[MY-IP]:8080   마무리(CONCLUSION)  Ubuntu 환경에 패키지로 Jenkins 설치를 완료했습니다.   Jenkins 초기 설정은 Jenkins 초기 설정하기 포스트를 참고하시기 바랍니다.   다음 포스트에서는 Ubuntu 환경에서 war 파일을 내려받아 java 명령어로 Jenkins를 실행하는 방법을 소개하겠습니다.   참고(REFERENCES)     https://jenkins.io/   http://pkg.jenkins-ci.org/debian-stable/  ","categories": ["jenkins"],
        "tags": ["jenkins","ubuntu"],
        "url": "https://lindarex.github.io/jenkins/ubuntu-jenkins-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "젠킨스(Jenkins) 초기 설정하기",
        "excerpt":"이 포스트에서는 우분투(이하 Ubuntu) 환경에 젠킨스(이하 Jenkins)를 설치한 후 초기 설정하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경에 Jenkins가 설치되어 있어야 합니다.      Jenkins 설치 방법은 우분투(Ubuntu) 환경에 패키지로 젠킨스(Jenkins) 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     Ubuntu 16.04.6 LTS (Xenial Xerus) Server (64-bit)   OpenJDK 1.8.0_242   Jenkins 2.204.2   요약(SUMMARY)     Jenkins 접속 및 활성화   Jenkins 추천 플러인(Plugin) 설치   관리자(Admin) 계정 등록   Jenkins 접속 URL 확인   OpenJDK(Java) 설정   내용(CONTENTS)  1. Jenkins 접속      2. Jenkins 활성화     아래 명령어로 Jenkins 활성화에 필요한 암호(Password)를 조회합니다.   $ sudo cat /var/lib/jenkins/secrets/initialAdminPassword 91623591371f4f57bf6814a674bfeda9      3. Jenkins 플러인(Plugin) 설치     ‘Install suggested plugins’를 선택합니다.         Plugin 설치를 진행합니다.      4. 관리자(Admin) 계정 등록      5. Jenkins 접속 URL 확인     포트(port) 번호를 포함한 전체 URL을 기재합니다.         Jenkins 사용을 위한 준비를 완료했습니다.         초기 설정 완료 후 Jenkins 첫 페이지로 이동합니다.      6. OpenJDK(Java) 설정     아래 메뉴를 통해 ‘Global Tool Configuration’ 페이지로 이동합니다.      Jenkins &gt; 왼쪽 상단 메뉴 &gt; Jenkins 관리 &gt; Global Tool Configuration                  JDK 설정              ‘JDK Installations’ 버튼을 클릭한 후, ‘Add JDK’ 버튼을 클릭합니다.       ‘Install automatically’을 체크해제하여, JDK name과 JAVA_HOME을 기재합니다.                  JAVA_HOME은 아래 명령어로 조회할 수 있습니다.         $ echo $JAVA_HOME  /usr/lib/jvm/java-8-openjdk-amd64                     마무리(CONCLUSION)  Jenkins 설치 후 초기 설정을 완료했습니다.   다음 포스트에서는 유용한 Jenkins Plugin을 소개하겠습니다.   참고(REFERENCES)     https://jenkins.io/   ","categories": ["jenkins"],
        "tags": ["jenkins"],
        "url": "https://lindarex.github.io/jenkins/jenkins-initial-setting/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 패키지로 PostgreSQL 설치하기",
        "excerpt":"PostgreSQL은 BSD 또는 MIT 라이선스와 유사한 PostgreSQL 라이선스로 오픈소스 소프트웨어로 배포됩니다.   PostgreSQL은 확장 가능성 및 표준 준수를 강조하는 객체-관계형 데이터베이스 관리 시스템(ORDBMS, object-relational database management system)으로, 트랜잭션과 ACID(Atomicity, Consistency, Isolation, Durability)를 지원합니다.   macOS 서버의 경우 PostgreSQL이 기본 데이터베이스이며, MS Windows와 리눅스에서도 이용할 수 있습니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 패키지로 PostgreSQL을 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경에 Java가 설치되어 있어야 합니다.   방화벽 설정이 필요합니다.            TCP 5432 포트가 개방되어 있어야 합니다.              Java 설치 방법은 우분투(Ubuntu) 환경에 OpenJDK(Java) 설치하기 포스트를 참고하시기 바랍니다.       방화벽 설정 방법은 우분투(Ubuntu) 환경에 방화벽(Firewalld) 설치 및 설정하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   PostgreSQL 11.5 (Ubuntu 11.5-3.pgdg18.04+1)   OpenJDK 1.8.0_222   요약(SUMMARY)     PostgreSQL debian packages repository 설정   apt 명령어로 PostgreSQL 설치   PostgreSQL 설정   systemctl 명령어로 PostgreSQL 실행   내용(CONTENTS)  1. PostgreSQL debian packages repository 추가  $ sudo sh -c 'echo \"deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main\" &gt; /etc/apt/sources.list.d/pgdg.list'   2. PostgreSQL debian packages repository key 추가  $ sudo wget -q https://www.postgresql.org/media/keys/ACCC4CF8.asc -O - | sudo apt-key add -   3. apt install 명령어로 PostgreSQL 설치  $ sudo apt update -y &amp;&amp; sudo apt install postgresql postgresql-contrib -y   4. PostgreSQL 설정      일반 사용자 계정으로 진행합니다.    4.1. PGDATA 디렉터리 생성  $ export LINDAREX_WORKSPACE=${HOME}/workspace $ mkdir -p ${LINDAREX_WORKSPACE}/pgsql/data   4.2. PGDATA 디렉터리 경로 추가  $ sudo vi /etc/profile   -------------------------------------------------------------------------------- export LINDAREX_WORKSPACE=/home/ubuntu/workspace export PGDATA=${LINDAREX_WORKSPACE}/pgsql/data --------------------------------------------------------------------------------      위 workspace(LINDAREX_WORKSPACE) 디렉터리 경로는 사용자 계정에 따라 다릅니다.       수정 내역 적용을 위해 아래 명령어를 입력합니다.    $ source /etc/profile      4.3. Database 초기화     아래 명령어로 Database 초기화를 실행합니다.   $ /usr/lib/postgresql/11/bin/initdb   4.4. PostgreSQL 설정 수정     아래 설정으로 외부 접속이 가능하게 합니다.   $ sudo vi /etc/postgresql/11/main/postgresql.conf   -------------------------------------------------------------------------------- listen_addresses = '*' --------------------------------------------------------------------------------      아래 설정으로 모든 사용자(비밀번호 사용)가 접속이 가능하게 합니다.   $ sudo vi /etc/postgresql/11/main/pg_hba.conf   -------------------------------------------------------------------------------- ## Add at the bottom host    all             all             0.0.0.0/0               password --------------------------------------------------------------------------------   5. systemctl 명령어로 PostgreSQL 서비스 관리  5.1. PostgreSQL 서비스 설정 반영  $ sudo systemctl daemon-reload   5.2. PostgreSQL 서비스 시작  $ sudo systemctl start postgresql.service   5.3. PostgreSQL 서비스 중지  $ sudo systemctl stop postgresql.service   5.4. PostgreSQL 서비스 재시작  $ sudo systemctl restart postgresql.service   5.5. PostgreSQL 서비스 설정 재적용  $ sudo systemctl reload postgresql.service   5.6. PostgreSQL 서비스 상태 조회  $ sudo systemctl status postgresql.service   5.7. PostgreSQL 서비스 활성화(부팅 시 자동 시작)  $ sudo systemctl enable postgresql.service   5.8. PostgreSQL 서비스 비활성화  $ sudo systemctl disable postgresql.service   5.9. PostgreSQL 서비스 및 관련 프로세스 모두 중지  $ sudo systemctl kill postgresql.service   마무리(CONCLUSION)  Ubuntu 환경에 패키지로 PostgreSQL 설치를 완료했습니다.   다음 포스트에서는 PostgreSQL 사용 방법을 소개하겠습니다.   참고(REFERENCES)     https://www.postgresql.org/   https://www.postgresql.org/download/linux/ubuntu/   https://ko.wikipedia.org/wiki/PostgreSQL   https://d2.naver.com/helloworld/227936  ","categories": ["postgresql"],
        "tags": ["postgresql","ubuntu"],
        "url": "https://lindarex.github.io/postgresql/ubuntu-postgresql-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 SonarQube 설치하기",
        "excerpt":"SonarQube는 정적 코드 분석기로 20개 이상의 프로그래밍 언어의 버그와 Code smells, 보안 취약점을 발견하고 자동 리뷰를 수행하여 지속적인 코드 품질 검사를 위한 플랫폼입니다.   SonarQube는 LGPL(Lesser GNU General Public License) 라이선스로 오픈소스 소프트웨어이며, 코드 커버리지, 유닛 테스트, 코딩 표준, 중복 코드, 코드 복잡도, 주석, 버그 및 보안 취약점의 보고서를 제공합니다.   또한 Maven, Ant, Gradle, MSBuild 및 CI(Continuous Integration) 도구인 Atlassian Bamboo, Jenkins, Hudson 등과의 연동을 제공합니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 SonarQube를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경에 PostgreSQL이 설치되어 있어야 합니다.   방화벽 설정이 필요합니다.            TCP 9000 포트가 개방되어 있어야 합니다.              PostgreSQL 설치 방법은 우분투(Ubuntu) 환경에 PostgreSQL 설치하기 포스트를 참고하시기 바랍니다.       방화벽 설정 방법은 우분투(Ubuntu) 환경에 방화벽(Firewalld) 설치 및 설정하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   SonarQube 7.9.1   PostgreSQL 11.5 (Ubuntu 11.5-3.pgdg18.04+1)   OpenJDK 1.8.0_222   요약(SUMMARY)     SonarQube 파일 내려받기   PostgreSQL 설정   SonarQube 설정   스크립트로 SonarQube 서비스 관리   웹브라우저로 SonarQube 접속   내용(CONTENTS)      아래 명령어로 workspace 디렉터리를 생성합니다.    $ export LINDAREX_WORKSPACE=${HOME}/workspace $ mkdir -p ${LINDAREX_WORKSPACE}   1. SonarQube 파일 내려받기  $ wget -P ${LINDAREX_WORKSPACE} https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-7.9.1.zip   2. 내려받은 파일 압축 해제  $ unzip -q ${LINDAREX_WORKSPACE}/sonarqube-7.9.1.zip -d ${LINDAREX_WORKSPACE}   3. Symbolic link 설정  $ ln -s ${LINDAREX_WORKSPACE}/sonarqube-7.9.1 ${LINDAREX_WORKSPACE}/sonarqube   4. PostgreSQL 설정     SonarQube와 연동 될 사용자 계정과 데이터베이스(이하 Database)를 생성합니다.   4.1. postgres 계정 로그인  $ sudo su - postgres   4.2. psql utility 실행  $ psql postgres   4.3. 사용자 생성  postgres=# create user sonar;   4.4. 사용자 Role 설정  postgres=# alter role sonar with createdb;   4.5. 사용자 비밀번호 설정  postgres=# alter user sonar with encrypted password 'sonar-password'; postgres=# alter user postgres password 'postgres-password';      생성한 사용자 정보를 조회합니다.    postgres=# \\du      4.6. Database 생성  postgres=# create database sonar owner sonar;   4.7. Privileges 설정  postgres=# grant all privileges on database sonar to sonar;      생성한 Database를 조회합니다.    postgres=# \\l      4.8. psql utility 종료  postgres=# \\q   4.9. postgres 계정 로그아웃  $ exit   5. SonarQube 설정     위에서 생성한 PostgreSQL 사용자 정보와 Database 정보, SonarQube UI의 포트를 설정합니다.   $ vi ${LINDAREX_WORKSPACE}/sonarqube/conf/sonar.properties   -------------------------------------------------------------------------------- sonar.jdbc.username=sonar sonar.jdbc.password=sonar-password sonar.jdbc.url=jdbc:postgresql://{MY-IP}/sonar sonar.web.port=9000 --------------------------------------------------------------------------------      OpenJDK(Java) 경로를 설정합니다.   $ vi ${LINDAREX_WORKSPACE}/sonarqube/conf/wrapper.conf   -------------------------------------------------------------------------------- wrapper.java.command=/home/rex/workspace/tool/java11/bin/java --------------------------------------------------------------------------------   6. Max map count 설정  $ sudo vi /etc/profile   -------------------------------------------------------------------------------- sudo sysctl -w vm.max_map_count=262144 --------------------------------------------------------------------------------      SonarQube를 Linux에 설치 시, 아래 사항이 요구됩니다.         vm.max_map_count :: 262144 이상     fs.file-max :: 65536 이상     file descriptors :: 65536 이상     threads :: 4096 이상         SonarQube 설치 시 필요 요구사항에 대한 자세한 정보는 https://docs.sonarqube.org/latest/requirements/requirements/를 확인해 주시기 바랍니다.       수정 내역 적용을 위해 아래 명령어를 입력합니다.    $ sudo source /etc/profile      7. 스크립트로 SonarQube 서비스 관리  7.1. SonarQube 서비스 시작  $ ${LINDAREX_WORKSPACE}/sonarqube/bin/linux-x86-64/sonar.sh start   7.2. SonarQube 서비스 중지  $ ${LINDAREX_WORKSPACE}/sonarqube/bin/linux-x86-64/sonar.sh stop   7.3. SonarQube 서비스 재시작  $ ${LINDAREX_WORKSPACE}/sonarqube/bin/linux-x86-64/sonar.sh restart   7.3. SonarQube 서비스 상태 조회  $ ${LINDAREX_WORKSPACE}/sonarqube/bin/linux-x86-64/sonar.sh status   8. 웹브라우저로 SonarQube 접속     http://[MY-IP]:9000   마무리(CONCLUSION)  Ubuntu 환경에 SonarQube 설치를 완료했습니다.   다음 포스트에서는 SonarQube 사용 방법과 유용한 플러그인을 소개하겠습니다.   참고(REFERENCES)     https://www.sonarqube.org/   https://docs.sonarqube.org/latest/   http://www.sonarqube.org/downloads/  ","categories": ["sonarqube"],
        "tags": ["sonarqube","ubuntu"],
        "url": "https://lindarex.github.io/sonarqube/ubuntu-sonarqube-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 SCM Manager 설치하기",
        "excerpt":"SCM Manager는 사설 버전관리 레파지토리(Private source code and version control repository)로 BSD 라이선스가 적용된 오픈소스 소프트웨어입니다.   SCM Manager는 Git과 Mercurial, Subversion을 지원하고, 다양한 플러그인과 RESTFul API를 제공합니다.   SCM Manager 설치는 Standalone 방식(tar, RPM, DEB package)과 WebApp(war) 방식을 제공하는데, 이 포스트에서는 우분투(이하 Ubuntu) 환경에서 Standalone 방식으로 SCM Manager를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경에 Java가 설치되어 있어야 합니다.   방화벽 설정이 필요합니다.            TCP 8080 포트가 개방되어 있어야 합니다.              Java 설치 방법은 우분투(Ubuntu) 환경에 OpenJDK(Java) 설치하기 포스트를 참고하시기 바랍니다.       방화벽 설정 방법은 우분투(Ubuntu) 환경에 방화벽(Firewalld) 설치 및 설정하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   SCM Manager 1.6.0   OpenJDK 1.8.0_222   요약(SUMMARY)     SCM Manager 파일 내려받기   SCM Manager 설정   스크립트로 SCM Manager 살행   웹브라우저로 SCM Manager 접속   내용(CONTENTS)      아래 명령어로 workspace 디렉터리를 생성합니다.    $ export LINDAREX_WORKSPACE=${HOME}/workspace $ mkdir -p ${LINDAREX_WORKSPACE}   1. SCM Manager 파일 내려받기  $ wget -P ${LINDAREX_WORKSPACE} https://maven.scm-manager.org/nexus/content/repositories/releases/sonia/scm//scm-server/1.60/scm-server-1.60-app.tar.gz   2. 내려받은 파일 압축 해제  $ tar zxf ${LINDAREX_WORKSPACE}/scm-server-1.60-app.tar.gz -C ${LINDAREX_WORKSPACE}   3. SCM Manager 설정      SCM Manager UI의 포트를 설정합니다.   $ vi ${LINDAREX_WORKSPACE}/scm-server/conf/server-config.xml   -------------------------------------------------------------------------------- &lt;SystemProperty name=\"jetty.port\" default=\"8080\" /&gt; --------------------------------------------------------------------------------   4. SCM Manager 실행  $ cd ${LINDAREX_WORKSPACE}/scm-server/bin/ $ nohup ./scm-server &gt; /dev/null &amp;   5. 웹브라우저로 SCM Manager 접속     http://[MY-IP]:8080   마무리(CONCLUSION)  Ubuntu 환경에 Standalone 방식으로 SCM Manager 설치를 완료했습니다.   다음 포스트에서는 SCM Manager 사용 방법을 소개하겠습니다.   참고(REFERENCES)     https://www.scm-manager.org/download/  ","categories": ["scm-manager"],
        "tags": ["scm manager","ubuntu"],
        "url": "https://lindarex.github.io/scm-manager/ubuntu-scm-manager-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 AWS CLI 설치하기",
        "excerpt":"AWS CLI(command line interface, 명령줄 인터페이스)는 AWS 서비스를 관리하는 통합 도구입니다.   Python 2.6.5 이상이 필요하며, pip을 사용하여 AWS CLI를 설치합니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 AWS를 사용하기 위한 AWS CLI를 설치하는 방법을 소개합니다.      pip은 파이썬(Python)으로 작성된 패키지 소프트웨어를 설치 및 관리하는 패키지 관리 시스템입니다.    선행조건(PREREQUISITE)     Ubuntu 환경이 필요합니다.      Ubuntu 설치 방법은 VMware workstation에 Ubuntu 16.04 설치하기 또는 VMware workstation에 Ubuntu 18.04 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   AWS CLI v1.16.261   Python v2.7.17   요약(SUMMARY)     apt 명령어로 pip 설치   pip 명령어로 AWS CLI 설치   내용(CONTENTS)  1. apt 명령어로 pip 설치  $ sudo apt install python-setuptools python-pip -y   2. pip 명령어로 AWS CLI 설치  $ pip install awscli      AWS CLI 설치 후 세션 재접속이 필요합니다.    마무리(CONCLUSION)  Ubuntu 환경에 AWS CLI 설치를 완료했습니다.   다음 포스트에서는 AWS CLI를 이용한 AWS S3 사용 방법을 소개하겠습니다.   참고(REFERENCES)     https://aws.amazon.com/ko/cli/  ","categories": ["aws"],
        "tags": ["aws","cli","ubuntu"],
        "url": "https://lindarex.github.io/aws/ubuntu-aws-cli-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "AWS EC2 우분투(Ubuntu) 환경에 BOSH director 설치하기",
        "excerpt":"Cloud Foundry BOSH는 소규모 및 대규모 클라우드 애플리케이션의 배포와 라이프 사이클 관리, release engineering을 통합하는 오픈소스 소프트웨어 프로젝트입니다.  BOSH는 수백 개의 가상머신(Virtual Machine, 이하 VM)에 애플리케이션을 프로비저닝(Provisioning)하고 배포할 수 있으며, 모니터링과 오류 복구, 애플리케이션 업데이트를 수행합니다.   BOSH는 Cloud Foundry PaaS(CFAR) 배포를 위해 개발되었지만, 거의 모든 소프트웨어를 배포하는 데에도 사용할 수 있습니다. 예를 들면, Hadoop 또는 Jenkins 등의 오픈소스 소프트웨어를 BOSH release로 작성하여 배포할 수 있으며 대규모 분산 시스템에 적합합니다.   또한 BOSH는 Amazon Web Services EC2, Google Cloud Platform, Microsoft Azure, OpenStack, VMware vSphere 및 Alibaba Cloud와 같은 다양한 IaaS(Infrastructure as a Service) provider를 지원하며, Apache CloudStack, VirtualBox 등의 IaaS provider 지원을 위해 CPI(Cloud Provider Interface)를 제공합니다.   이 포스트에서는 AWS EC2 우분투(이하 Ubuntu) 환경에서 BOSH 사용을 위한 BOSH director를 설치하는 방법을 소개합니다.      CFAR에 대해서는 본문의 CF CLI 설치에서 설명합니다.    선행조건(PREREQUISITE)     AWS 환경이 필요합니다.            VPC 설정이 필요합니다.       Subnet 설정이 필요합니다.       Internet gateway 설정이 필요합니다.       NAT Gateway 설정이 필요합니다.       Routing table 설정이 필요합니다.       security group 설정이 필요합니다.       Quota 설정이 필요합니다.           AWS EC2 Inception VM이 필요합니다.      BOSH director 설치를 위한 AWS 환경 설정 및 AWS EC2 Inception VM 생성 방법은 다음 포스트에서 소개하겠습니다.       AWS, GCP, MS Azure, OpenStack, VMware vSphere 등 IaaS 환경에 BOSH director를 설치하여 BOSH를 사용하거나, 로컬(이하 local) 환경에 BOSH-LITE를 설치하여 BOSH를 사용할 수 있습니다.       Provisioning이란 사용자의 요구에 맞게 시스템 자원을 할당, 배치, 배포해 두었다가 필요 시 시스템을 즉시 사용할 수 있는 상태로 미리 준비해 두는 것을 의미합니다.       Provisioning에 대한 자세한 정보는 https://ko.wikipedia.org/wiki/프로비저닝, https://en.wikipedia.org/wiki/Provisioning_(telecommunications)를 확인해 주시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     AWS EC2   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   요약(SUMMARY)     BOSH CLI 설치   (선택사항) CF CLI 설치   CF UAA CLI 설치   Credhub CLI 설치   BOSH director 설치   BOSH UAA 통합 인증   BOSH director 설정   BOSH jumpbox 설정   Credhub 설정   내용(CONTENTS)      아래 명령어로 환경변수를 설정하고, workspace 디렉터리를 생성합니다.    $ export LINDAREX_INCEPTION_USER_NAME='ubuntu' $ export LINDAREX_BOSH_WORKSPACE=/home/${LINDAREX_INCEPTION_USER_NAME}/workspace $ export LINDAREX_BOSH_DIRECTOR='micro-bosh' $ export LINDAREX_BOSH_IAAS='aws' $ mkdir -p ${LINDAREX_BOSH_WORKSPACE}   1. BOSH CLI 설치하기     BOSH CLI는 v1 버전과 v2 버전이 존재하며, 이 포스트에서는 v2 버전을 기준으로 설명합니다.   1.1. 종속 패키지 설치     자신이 사용하는 Ubuntu 버전에 따라 아래 명령어로 종속 패키지(Package dependencies)를 설치합니다.      Ubuntu 18.04 (Bionic)    $ sudo apt update -y $ sudo apt install -y build-essential zlibc zlib1g-dev ruby ruby-dev openssl libxslt1-dev libxml2-dev libssl-dev libreadline7 libreadline-dev libyaml-dev libsqlite3-dev sqlite3      Ubuntu 16.04 (Xenial) 또는 Ubuntu Trusty (14.04)    $ sudo apt update -y $ sudo apt install -y libcurl4-openssl-dev gcc g++ build-essential zlibc zlib1g-dev ruby ruby-dev openssl libxslt-dev libxml2-dev libssl-dev libreadline6 libreadline6-dev libyaml-dev libsqlite3-dev sqlite3   1.2. BOSH CLI 파일 내려받기  $ curl -Lo ${LINDAREX_BOSH_WORKSPACE}/bosh https://github.com/cloudfoundry/bosh-cli/releases/download/v6.2.1/bosh-cli-6.2.1-linux-amd64   1.3. chmod(change mode) 명령어로 파일 권한 변경(실행 권한 부여)  $ chmod +x ${LINDAREX_BOSH_WORKSPACE}/bosh   1.4. 실행 파일을 사용자 프로그램 경로로 옮기기  $ sudo mv ${LINDAREX_BOSH_WORKSPACE}/bosh /usr/local/bin/bosh   1.5. BOSH CLI 설치 확인  $ bosh -v version 6.2.1-a28042ac-2020-02-10T18:40:57Z  Succeeded   2. (선택사항) CF CLI 설치하기     CF CLI에서 CF는 정확히 표현하면 CFAR(cloud foundry application runtime)입니다.   CF CLI는 CFAR 명령어를 사용하기 위한 설치입니다.   CFAR은 BOSH로 배포하며, 다음 포스트에서 소개하겠습니다.      CFAR은 CFCR(cloud foundry container runtime)이 생기기 전까지 CF(cloud foundry)로 불렸었고, CFCR도 Cloud Foundry Foundation incubating project 초반에는 kubo로 불렸습니다.       최근 컨테이너 플랫폼(Container platform)의 성장과 함께 Cloud Foundry도 kubernetes를 이용한 container runtime을 제공하면서, application runtime인 CF를 CFAR로, container runtime인 kubo를 CFCR로 명칭을 변경했습니다.    2.1. CF CLI Debian packages repository key 추가  $ wget -q -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -   2.2. CF CLI Debian packages repository 추가  $ echo \"deb https://packages.cloudfoundry.org/debian stable main\" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list   2.3. apt install 명령어로 CF CLI 설치  $ sudo apt update -y &amp;&amp; sudo apt install cf-cli -y   2.4. CF CLI 설치 확인  $ cf --version cf version 6.49.0+d0dfa93bb.2020-01-07   3. CF UAA CLI 설치하기     UAA는 사용자 계정 및 인증 서버(User Account and Authentication server)입니다.   UAA는 CFAR과 BOSH에 각각 존재하며 CF UAA CLI를 통해 모두 사용할 수 있습니다.   3.1. Rubygems으로 CF UAA CLI 설치  $ sudo gem install cf-uaac   3.2. CF UAA CLI 설치 확인  $ uaac -v UAA client 4.2.0   4. Credhub CLI 설치     CredHub는 비밀번호, 인증서(certificates), 인증 기관(certificate authorities), ssh 키, rsa 키와 같은 credentials 정보를 관리합니다.   4.1. Credhub CLI 파일 내려받기  $ wget -P ${LINDAREX_BOSH_WORKSPACE} https://github.com/cloudfoundry-incubator/credhub-cli/releases/download/2.6.2/credhub-linux-2.6.2.tgz   4.2. 내려받은 파일 압축 해제  $ tar zxf ${LINDAREX_BOSH_WORKSPACE}/credhub-linux-2.6.2.tgz -C ${LINDAREX_BOSH_WORKSPACE}   4.3. chmod 명령어로 파일 권한 변경(실행 권한 부여)  $ chmod +x ${LINDAREX_BOSH_WORKSPACE}/credhub   4.4. 실행 파일을 사용자 프로그램 경로로 옮기기  $ sudo mv ${LINDAREX_BOSH_WORKSPACE}/credhub /usr/local/bin/credhub   4.5. Credhub CLI 설치 확인  $ credhub --version CLI Version: 2.6.2 Server Version: Not Found. Have you targeted and authenticated against a CredHub server?   5. BOSH director 설치  5.1. BOSH deployment repository clone 받기  $ git clone https://github.com/cloudfoundry/bosh-deployment.git ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment      Cloud Foundry github repository에서 제공하는 BOSH deployment는 branch나 tag가 존재하지 않습니다. Clone 받는 당시의 버전으로 설치를 해야 하며, 간혹 오류를 포함한 버전도 배포되곤 합니다.    5.2. 배포 스크립트 작성  $ vi ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/deploy-${LINDAREX_BOSH_IAAS}.sh   -------------------------------------------------------------------------------- #!/bin/bash  bosh create-env bosh.yml \\ \t--state=aws/state.json \\ \t--vars-store=aws/creds.yml \\ \t-o aws/cpi.yml \\ \t-o uaa.yml \\ \t-o credhub.yml \\ \t-o jumpbox-user.yml \\ \t-v internal_cidr='10.0.1.0/24' \\ \t-v internal_gw='10.0.1.1' \\ \t-v internal_ip='10.0.1.6' \\ \t-v director_name='micro-bosh' \\ \t-v access_key_id='AKIBI7UEWB42Q4THBBFQ' \\ \t-v secret_access_key='br3K3YQM7SwvyP/0G4AJozpSLUFwaBxy+KRFy+3q' \\ \t-v region='ap-northeast-2' \\ \t-v az='ap-northeast-2c' \\ \t-v default_key_name='lindarex-inception' \\ \t-v default_security_groups=[lindarex-security] \\ \t-v subnet_id='subnet-087f7203d0bcd1396' \\ \t-v private_key='~/.ssh/lindarex-inception.pem' --------------------------------------------------------------------------------      ‘-o’ 옵션은 YAML로 작성된 옵션 파일의 경로를 지정하여 배포 시에 적용합니다.        ‘-v’ 옵션은 변수를 설정하여 배포 시에 적용합니다.       배포 스크립트를 상세하게 설명하겠습니다.            ‘create-env’ :: BOSH director를 배포하는 명령어입니다.       ‘bosh.yml’ :: 설정한 YAML 파일을 기반으로 Single VM을 생성합니다.       ’–state’ :: 배포 상태 파일의 경로입니다.       ’–vars-store’ :: Credentials 정보를 저장하는 YAML 파일의 경로입니다.       ‘-o aws/cpi.yml’ :: AWS CPI를 적용합니다. IaaS 마다 CPI가 다릅니다.       ‘-o uaa.yml’ :: UAA를 적용합니다.       ‘-o credhub.yml’ :: Credhub을 적용합니다.       ‘-o jumpbox-user.yml’ :: Jumpbox user를 적용합니다. BOSH director VM에 SSH 접속을 할 수 있습니다.       ‘-v internal_cidr’ :: BOSH director VM에 적용할 네트워크의 cidr입니다.       ‘-v internal_gw’ :: BOSH director VM에 적용할 네트워크의 gateway ip입니다.       ‘-v internal_ip’ :: BOSH director VM에 적용할 네트워크의 private ip입니다.       ‘-v director_name’ :: BOSH director 명입니다.       ‘-v access_key_id’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS access key id입니다.       ‘-v secret_access_key’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS secret access key입니다.       ‘-v region’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS region입니다.       ‘-v az’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS az(availability zone, 가용 영역)입니다.       ‘-v default_key_name’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS key name입니다.       ‘-v default_security_groups’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS security_group입니다.       ‘-v subnet_id’ :: IaaS가 AWS인 경우 필요한 변수이며, BOSH director VM에 적용할 네트워크의 subnet id입니다.       ‘-v private_key’ :: IaaS가 AWS인 경우 필요한 변수이며, AWS private key 파일의 경로입니다.              위 배포 스크립트는 AWS 서울 region에 배포되는 설정이지만, region과 az를 제외한 AWS 설정값은 잘못된 값이므로 참고만 하시기를 바랍니다.    5.3. chmod 명령어로 파일 권한 변경(실행 권한 부여)  $ chmod +x ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/deploy-${LINDAREX_BOSH_IAAS}.sh   5.4. (선택사항) 배포 상태 파일 삭제  $ rm -rf ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/state.json $ rm -rf ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml      state.json 파일과 creds.yml 파일은 배포 성공 여부와 관계없이 ‘bosh create-env’ 명령어를 한 번이라도 실행하면 생성되는 파일입니다.    5.5. 배포 스크립트 실행  $ cd ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment $ ./deploy-${LINDAREX_BOSH_IAAS}.sh   6. BOSH UAA 통합 인증  6.1. BOSH UAA target 설정  $ uaac target https://10.0.1.6:8443 --skip-ssl-validation Unknown key: Max-Age = 86400  Target: https://10.0.1.6:8443    6.2. Client credentials grant를 통해 UAA admin token 얻기  $ uaac token client get uaa_admin -s `bosh int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /uaa_admin_client_secret` Unknown key: Max-Age = 86400  Successfully fetched token via client credentials grant. Target: https://10.0.1.6:8443 Context: uaa_admin, from client uaa_admin    6.3. UAA admin token 파싱 및 clients 목록 조회  $ uaac token decode &amp;&amp; uaac clients  Note: no key given to validate token signature    jti: 1b82b1e6cfbb4606a182d5ab88c28b8d   sub: uaa_admin   authorities: clients.read password.write clients.secret clients.write uaa.admin scim.write scim.read   scope: clients.read password.write clients.secret clients.write uaa.admin scim.write scim.read   client_id: uaa_admin   cid: uaa_admin   azp: uaa_admin   revocable: true   grant_type: client_credentials   rev_sig: 34bac1ad   iat: 1573525863   exp: 1573569063   iss: https://10.0.1.6:8443/oauth/token   zid: uaa   aud: scim uaa_admin password clients uaa   admin     scope: uaa.none     resource_ids: none     authorized_grant_types: client_credentials     autoapprove:     authorities: bosh.admin     lastmodified: 1573525068032   bosh_cli     scope: openid bosh.admin bosh.read bosh.*.admin bosh.*.read bosh.teams.*.admin bosh.teams.*.read     resource_ids: none     authorized_grant_types: password refresh_token     autoapprove:     access_token_validity: 120     refresh_token_validity: 86400     authorities: uaa.none     lastmodified: 1573525068153   credhub-admin     scope: uaa.none     resource_ids: none     authorized_grant_types: client_credentials     autoapprove:     access_token_validity: 3600     authorities: credhub.write credhub.read     lastmodified: 1573525068271   credhub_cli     scope: credhub.read credhub.write     resource_ids: none     authorized_grant_types: password refresh_token     autoapprove:     access_token_validity: 60     refresh_token_validity: 1800     authorities: uaa.none     lastmodified: 1573525068386   director_to_credhub     scope: uaa.none     resource_ids: none     authorized_grant_types: client_credentials     autoapprove:     access_token_validity: 3600     authorities: credhub.write credhub.read     lastmodified: 1573525068492   hm     scope: uaa.none     resource_ids: none     authorized_grant_types: client_credentials     autoapprove:     authorities: bosh.admin     lastmodified: 1573525068590   uaa_admin     scope: uaa.none     resource_ids: none     authorized_grant_types: client_credentials     autoapprove:     authorities: clients.read password.write clients.secret clients.write uaa.admin scim.write scim.read     lastmodified: 1573525068689   7. BOSH director 설정  7.1. Local alias 설정  $ export BOSH_CLIENT='admin' $ export BOSH_CLIENT_SECRET=`bosh int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /admin_password` $ bosh alias-env ${LINDAREX_BOSH_DIRECTOR} -e 10.0.1.6 --ca-cert &lt;(bosh int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /director_ssl/ca)   7.2. BOSH 로그인  $ bosh -e ${LINDAREX_BOSH_DIRECTOR} l Successfully authenticated with UAA  Succeeded   7.3. BOSH director 정보 조회  $ bosh -e ${LINDAREX_BOSH_DIRECTOR} env Using environment '10.0.1.6' as client 'admin'  Name               micro-bosh UUID               b002986f-3a05-441a-be08-3a46dbe29a8a Version            270.5.0 (00000000) Director Stemcell  ubuntu-xenial/456.27 CPI                aws_cpi Features           compiled_package_cache: disabled                    config_server: enabled                    local_dns: enabled                    power_dns: disabled                    snapshots: disabled User               admin  Succeeded   7.4. (선택사항) 사용자 프로필에 BOSH director 정보 추가  $ vi $HOME/.profile   -------------------------------------------------------------------------------- export LINDAREX_INCEPTION_USER_NAME='ubuntu' export LINDAREX_BOSH_WORKSPACE=/home/${LINDAREX_INCEPTION_USER_NAME}/workspace export LINDAREX_BOSH_DIRECTOR='micro-bosh' export LINDAREX_BOSH_IAAS='aws' export BOSH_ENVIRONMENT='10.0.1.6' export BOSH_CLIENT='admin' export BOSH_CLIENT_SECRET=`bosh -e ${LINDAREX_BOSH_DIRECTOR} int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /admin_password` --------------------------------------------------------------------------------      수정 내역 적용을 위해 아래 명령어를 입력합니다.    $ source $HOME/.profile      8. BOSH jumpbox 설정  8.1. Jumpbox key 생성  $ cd ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment $ bosh int ${LINDAREX_BOSH_IAAS}/creds.yml --path /jumpbox_ssh/private_key &gt; jumpbox.key   8.2. chmod 명령어로 파일 권한 변경(소유자만 읽기 및 쓰기 권한 부여)  $ chmod 600 jumpbox.key   8.3. BOSH director VM에 SSH 접속  $ ssh jumpbox@${BOSH_ENVIRONMENT} -i ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/jumpbox.key The authenticity of host '10.0.1.6 (10.0.1.6)' can't be established. ECDSA key fingerprint is SHA256:Lc0OsEocqPAEgAk0c1X7Y7y+iNWqeFMGkfFFLRlA8ww. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added '10.0.1.6' (ECDSA) to the list of known hosts. Unauthorized use is strictly prohibited. All access and activity is subject to logging and monitoring. Welcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.15.0-54-generic x86_64)   * Documentation:  https://help.ubuntu.com  * Management:     https://landscape.canonical.com  * Support:        https://ubuntu.com/advantage  The programs included with the Ubuntu system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright.  Ubuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law.  Last login: Tue Feb 18 07:23:17 2020 from 10.0.201.149 To run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\". See \"man sudo_root\" for details.  bosh/0:~$    8.4. BOSH director VM의 외부 통신 상태 확인  bosh/0:~$ sudo ping 8.8.8.8 PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data. 64 bytes from 8.8.8.8: icmp_seq=1 ttl=53 time=30.8 ms 64 bytes from 8.8.8.8: icmp_seq=2 ttl=53 time=29.1 ms ^C --- 8.8.8.8 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1000ms rtt min/avg/max/mdev = 29.135/30.009/30.884/0.891 ms   bosh/0:~$ wget https://wordpress.org/latest.zip      아래 명령어로 BOSH director VM의 SSH 접속을 종료할 수 있습니다.    bosh/0:~$ exit logout Connection to 10.0.1.6 closed.      9. Credhub 설정  9.1. Credhub api server 설정  $ credhub api \\ --ca-cert=&lt;(bosh int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /credhub_ca/ca) \\ --ca-cert=&lt;(bosh int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /uaa_ssl/ca) \\ --server=10.0.1.6:8844 Setting the target url: https://10.0.1.6:8844   9.2. Credhub 로그인  $ credhub login --client-name=credhub-admin --client-secret=`bosh int ${LINDAREX_BOSH_WORKSPACE}/bosh-deployment/${LINDAREX_BOSH_IAAS}/creds.yml --path /credhub_admin_client_secret` Login Successful   9.3. credentials 전체 조회  $ credhub find credentials: []   마무리(CONCLUSION)  AWS EC2 Ubuntu 환경에 BOSH director 설치를 완료했습니다.   BOSH director 설치는 CFAR 및 CFCR 등 BOSH release 배포를 위한 기반 작업이며, 설치 진행을 위해서는 적지 않은 IaaS 설정이 필요합니다.   다음 포스트에서는 BOSH director 설치를 위한 AWS 환경 설정과 AWS EC2 Inception VM 생성 방법, BOSH components에 대한 설명과 BOSH release 작성 방법을 소개하겠습니다.   참고(REFERENCES)     https://bosh.io/docs/cli-v2-install/   https://github.com/cloudfoundry/bosh-cli/releases   https://docs.cloudfoundry.org/cf-cli/install-go-cli.html   https://github.com/cloudfoundry/cf-uaac   https://github.com/cloudfoundry-incubator/credhub-cli   ","categories": ["bosh"],
        "tags": ["bosh","ubuntu","aws","ec2"],
        "url": "https://lindarex.github.io/bosh/ubuntu-bosh-director-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "Travis CI로 Jekyll 블로그를 GitHub Pages에 자동 배포하기",
        "excerpt":"이 포스트에서는 Travis CI(이하 travis)를 이용해 Jekyll 블로그(이하 jekyll)를 GitHub Pages에 자동 배포하는 방법을 소개합니다.   선행조건(PREREQUISITE)     GitHub 계정이 필요합니다.   GitHub Pages의 브랜치(이하 branch)는 빌드(이하 build) 후 배포되는 master branch, jekyll code를 올릴 sources branch로 구성합니다.   테스트 환경(TEST ENVIRONMENT)     Chrome v80.0.3987.116(공식 빌드) (64비트)   Firefox Browser v74.0b5 (64-비트)   요약(SUMMARY)     GitHub Personal access token 생성   Travis CI 설정   travis.yml 파일 작성   배포 확인   내용(CONTENTS)  1. GitHub Personal access token(이하 token) 생성     https://github.com/에 접속합니다.       우측 상단의 Profile 아이콘을 선택하여 ‘Settings’ 페이지로 이동합니다.         좌측 중간에 Personal access tokens 메뉴를 클릭합니다.         GitHub 계정의 비밀번호를 입력합니다.         token 이름을 입력하고, token으로 접근 가능한 Scope(repo 전체)를 체크하고, 화면 하단의 ‘Generate token’을 클릭합니다.            생성된 token 값은 travis 설정에 필요하기 때문에 메모해 둡니다.      2. Travis CI 설정      https://github.com/apps/travis-ci에 접속합니다.       우측 상단의 ‘Install’을 클릭합니다.         ‘Only select repositories’ 영역의 ‘Select repositories’를 클릭하여 travis를 연결할 레파지토리(이하 repository를 선택하고 ‘Install’을 클릭합니다.         travis가 GitHub repository에 접근할 수 있도록 권한 부여에 승인합니다.            https://travis-ci.com/으로 이동하여 승인이 진행됩니다.         우측 하단의 ‘Settings’를 클릭합니다.         ‘Environment Variables’ 영역에서 아래와 같이 입력하고 ‘Add’를 클릭합니다.            Name :: LINDAREX_GITHUB_TOKEN       Value :: 메모해 두었던 token              위 Name은 임의로 입력해도 무관합니다. 단, 이후 travis 설정과 동일해야 합니다.       3. travis.yml 파일 작성      실제 생성하는 파일명은 ‘.travis.yml’입니다.       아래와 같이 ‘.travis.yml’ 파일을 작성하여 jekyll 최상위 디렉터리(index.html 파일이 있는 경로)에 저장합니다.   travis 설정 시 Environment Variable에 입력한 name과 아래 github_token 값이 동일해야 합니다.   language: ruby rvm: - 2.3.3  script: bundle install &amp;&amp; bundle exec jekyll build  exclude: [vendor]  deploy:   provider: pages   skip_cleanup: true   github_token: $LINDAREX_GITHUB_TOKEN   keep_history: true   local-dir: ./_site   target-branch: master   on:     branch: sources  branches:   only:   - sources    4. 배포 확인     설정 완료 후, travis 첫 페이지으로 이동합니다.         로컬의 sources branch를 원격 저장소로 Push 하면, travis에서 build하여 master branch로 자동 배포됩니다.         build 중입니다.         정상 배포되었습니다.      마무리(CONCLUSION)  travis로 jekyll을 GitHub Pages에 자동 배포하는 방법을 완료했습니다.   다음 포스트에서는 travis로 다른 언어를 배포하는 방법을 소개하겠습니다.   참고(REFERENCES)     https://travis-ci.com/   ","categories": ["travis-ci"],
        "tags": ["travis ci","github pages","jekyll"],
        "url": "https://lindarex.github.io/travis-ci/travis-github-pages-jekyll-setting/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 패키지로 Azure CLI 설치하기",
        "excerpt":"Azure CLI(command line interface, 명령줄 인터페이스, 이하 azure cli)는 Microsoft Azure(이하 azure)에 리소스를 만들고 관리할 수 도구입니다.   모든 azure 서비스에서 사용할 수 있으며, azure를 빠르게 사용할 수 있도록 자동화에 초점을 두고 있습니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 패키지로 azure cli를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경이 필요합니다.      Ubuntu 설치 방법은 VMware workstation에 Ubuntu 16.04 설치하기 또는 VMware workstation에 Ubuntu 18.04 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   요약(SUMMARY)     azure cli debian packages repository 설정   apt 명령어로 azure cli 설치   azure cli 로그인   (선택사항) apt 명령어로 azure cli 삭제   내용(CONTENTS)  1. 종속 패키지 설치      Ubuntu 18.04 (Bionic)    $ sudo apt update $ sudo apt install -y ca-certificates curl apt-transport-https lsb-release gnupg   2. Microsoft 서명 키 설치  $ curl -sL https://packages.microsoft.com/keys/microsoft.asc | \\     gpg --dearmor | \\     sudo tee /etc/apt/trusted.gpg.d/microsoft.asc.gpg &gt; /dev/null   3. azure cli debian packages repository 추가  $ AZ_REPO=$(lsb_release -cs) $ echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $AZ_REPO main\" | \\     sudo tee /etc/apt/sources.list.d/azure-cli.list   4. azure cli 설치  $ sudo apt update $ sudo apt install azure-cli -y   5. azure 로그인  $ az login To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code HGCW1YCF3 to authenticate.   [   {     \"cloudName\": \"AzureCloud\",     \"id\": \"cd85e66d-8955-67b9-cdb5-cb6b706eb6b9\",     \"isDefault\": true,     \"name\": \"Microsoft Azure-LindaRex\",     \"state\": \"Enabled\",     \"tenantId\": \"2a755963-e627-665a-b039-ba6576750ae1\",     \"user\": {       \"name\": \"lindarex@lindarex.github.io\",       \"type\": \"user\"     }   } ]      위 로그인 결과는 잘못된 값이므로 참고만 하시기를 바랍니다.    6. (선택사항) azure cli 삭제  $ sudo apt remove azure-cli -y $ sudo apt autoremove -y $ sudo rm /etc/apt/sources.list.d/azure-cli.list $ sudo rm /etc/apt/trusted.gpg.d/microsoft.asc.gpg   마무리(CONCLUSION)  Ubuntu 환경에 패키지로 azure cli 설치를 완료했습니다.   다음 포스트에서는 azure 사용을 위한 service principal, resource group, network security group, virtual network, subnet, storage account 등의 설정과 Inception VM 생성 방법을 소개하겠습니다.   참고(REFERENCES)     https://docs.microsoft.com/ko-kr/cli/azure/?view=azure-cli-latest  ","categories": ["azure"],
        "tags": ["azure","cli","ubuntu"],
        "url": "https://lindarex.github.io/azure/ubuntu-azure-cli-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 패키지로 Elastic Stack 설치하기",
        "excerpt":"Elastic Stack을 소개하기에 앞서 ELK Stack을 먼저 소개하겠습니다.   ELK Stack은 Elasticsearch, Logstash, Kibana의 연동으로 텍스트, 숫자, 위치 기반 정보, 정형 및 비정형 데이터 등 모든 유형의 데이터를 수집 및 변환하고 분석하여 시각화하는 오픈소스 소프트웨어입니다.   2015년에 ELK Stack에 경량의 단일 목적 데이터 수집기 제품군(Beats)을 도입하면서 Elastic Stack(이하 elk)으로 명칭이 변경되었습니다.   즉, ELK Stack에 Beats가 추가되어 Elastic Stack으로 통합되었습니다.   이 포스트에서는 우분투(이하 Ubuntu) 환경에서 패키지로 elk를 설치하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경에 Java가 설치되어 있어야 합니다.   방화벽 설정이 필요합니다.            TCP 9200 포트, TCP 5601 포트가 개방되어 있어야 합니다.              Java 설치 방법은 우분투(Ubuntu) 환경에 OpenJDK(Java) 설치하기 포스트를 참고하시기 바랍니다.       방화벽 설정 방법은 우분투(Ubuntu) 환경에 방화벽(Firewalld) 설치 및 설정하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 16.04.6 LTS (Xenial Xerus) Server (64-bit)   Elasticsearch 7.2.0   Logstash 7.2.0   Kibana 7.2.0   Filebeat 7.2.0   OpenJDK 1.8.0_212   요약(SUMMARY)     Elasticsearch 설치   Logstash 설치   Kibana 설치   Filebeat 설치   웹브라우저로 Kibana 접속   내용(CONTENTS)  1. Elasticsearch 설치     Elasticsearch는 Apache Lucene으로 구축된 JSON 기반의 분산형 오픈소스 RESTful 검색 분석 엔진이며, Logstash를 통해 수신된 데이터를 저장소에 저장하는 역할을 담당합니다.   1.1. Elasticsearch debian packages repository 추가  $ echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list   1.2. Elasticsearch debian packages repository key 추가  $ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -   1.3. apt install 명령어로 Elasticsearch 설치  $ sudo apt update -y &amp;&amp; sudo apt install elasticsearch -y   1.4. systemctl 명령어로 Elasticsearch 서비스 관리  1.4.1. Elasticsearch 서비스 설정 반영  $ sudo systemctl daemon-reload   1.4.2. Elasticsearch 서비스 시작  $ sudo systemctl start elasticsearch.service   1.4.3. Elasticsearch 서비스 중지  $ sudo systemctl stop elasticsearch.service   1.4.4. Elasticsearch 서비스 재시작  $ sudo systemctl restart elasticsearch.service   1.4.5. Elasticsearch 서비스 설정 재적용  $ sudo systemctl reload elasticsearch.service   1.4.6. Elasticsearch 서비스 상태 조회  $ sudo systemctl status elasticsearch.service   1.4.7. Elasticsearch 서비스 활성화(부팅 시 자동 시작)  $ sudo systemctl enable elasticsearch.service   1.4.8. Elasticsearch 서비스 비활성화  $ sudo systemctl disable elasticsearch.service   1.4.9. Elasticsearch 서비스 및 관련 프로세스 모두 중지  $ sudo systemctl kill elasticsearch.service   1.5. curl 명령어로 Elasticsearch 서비스 확인  $ curl -X GET http://localhost:9200 {   \"name\" : \"lindarex-elk\",   \"cluster_name\" : \"elasticsearch\",   \"cluster_uuid\" : \"RXW_zgPsS9mWiB5CDi2aCQ\",   \"version\" : {     \"number\" : \"7.2.0\",     \"build_flavor\" : \"default\",     \"build_type\" : \"deb\",     \"build_hash\" : \"508c38a\",     \"build_date\" : \"2020-02-20T15:54:18.811730Z\",     \"build_snapshot\" : false,     \"lucene_version\" : \"8.0.0\",     \"minimum_wire_compatibility_version\" : \"6.8.0\",     \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"   },   \"tagline\" : \"You Know, for Search\" }   2. Logstash 설치     Logstash는 서버 사이드 데이터 처리 파이프라인으로, 여러 다양한 소스에서 동시에 데이터를 수집 및 변환하여 Elasticsearch와 같은 stash 보관소로 전송합니다.   2.1. (선택사항) SSL certificate 생성  2.1.1. Hostname or FQDN 설정  $ cd /etc/ssl/ $ sudo openssl req -x509 -nodes -newkey rsa:2048 -days 365 -keyout logstash-forwarder.key -out logstash-forwarder.crt -subj /CN=server.lindarex.local   2.1.2. IP Address 설정  $ sudo vi /etc/ssl/openssl.cnf   -------------------------------------------------------------------------------- ... [ v3_ca ] subjectAltName = IP:192.168.10.20 ... --------------------------------------------------------------------------------   $ cd /etc/ssl/ $ sudo openssl req -x509 -days 365 -batch -nodes -newkey rsa:2048 -keyout logstash-forwarder.key -out logstash-forwarder.crt   2.1.3. SSL 변환  $ cd /etc/ssl/ $ sudo openssl pkcs8 -in logstash-forwarder.key  -topk8 -nocrypt -out logstash-forwarder.key.pem $ sudo chmod 644 /etc/ssl/logstash-forwarder.key.pem   2.2. apt install 명령어로 Logstash 설치  $ sudo apt install logstash -y   2.3. Logstash 구성  $ sudo vi /etc/logstash/conf.d/logstash.conf   -------------------------------------------------------------------------------- input {  beats {    port =&gt; 5044        # Set to False if you do not SSL // (선택사항) SSL 미사용 시에 'false' 설정    ssl =&gt; true       # Delete below lines if no SSL is used  // (선택사항) SSL 미사용 시에 아래 설정 삭제    ssl_certificate =&gt; \"/etc/ssl/logstash-forwarder.crt\"    ssl_key =&gt; \"/etc/ssl/logstash-forwarder.key.pem\"    } }  filter { if [type] == \"syslog\" {     grok {       match =&gt; { \"message\" =&gt; \"%{SYSLOGLINE}\" }     }      date { match =&gt; [ \"timestamp\", \"MMM  d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] }   }  }  output {  elasticsearch {   hosts =&gt; localhost     index =&gt; \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\"        } stdout {     codec =&gt; rubydebug        } } --------------------------------------------------------------------------------   2.4. systemctl 명령어로 Logstash 서비스 관리  2.4.1. Logstash 서비스 설정 반영  $ sudo systemctl daemon-reload   2.4.2. Logstash 서비스 시작  $ sudo systemctl start logstash.service   2.4.3. Logstash 서비스 중지  $ sudo systemctl stop logstash.service   2.4.4. Logstash 서비스 재시작  $ sudo systemctl restart logstash.service   2.4.5. Logstash 서비스 설정 재적용  $ sudo systemctl reload logstash.service   2.4.6. Logstash 서비스 상태 조회  $ sudo systemctl status logstash.service   2.4.7. Logstash 서비스 활성화(부팅 시 자동 시작)  $ sudo systemctl enable logstash.service   2.4.8. Logstash 서비스 비활성화  $ sudo systemctl disable logstash.service   2.4.9. Logstash 서비스 및 관련 프로세스 모두 중지  $ sudo systemctl kill logstash.service   3. Kibana 설치     Kibana는 프런트 엔드 애플리케이션으로, Elasticsearch에서 인덱스 된 데이터 검색 및 다양한 차트와 그래프를 제공하고, 실시간으로 데이터를 분석하여 시각화를 담당합니다.   3.1. apt install 명령어로 Kibana 설치  $ sudo apt install kibana -y   3.2. Kibana 구성  $ sudo vi /etc/kibana/kibana.yml   -------------------------------------------------------------------------------- ... #server.host: \"localhost\" server.host: \"192.168.10.20\" #elasticsearch.hosts: [\"http://localhost:9200\"] elasticsearch.hosts: [\"http://localhost:9200\"] ... --------------------------------------------------------------------------------   3.3. systemctl 명령어로 Kibana 서비스 관리  3.3.1. Kibana 서비스 설정 반영  $ sudo systemctl daemon-reload   3.3.2. Kibana 서비스 시작  $ sudo systemctl start kibana.service   3.3.3. Kibana 서비스 중지  $ sudo systemctl stop kibana.service   3.3.4. Kibana 서비스 재시작  $ sudo systemctl restart kibana.service   3.3.5. Kibana 서비스 설정 재적용  $ sudo systemctl reload kibana.service   3.3.6. Kibana 서비스 상태 조회  $ sudo systemctl status kibana.service   3.3.7. Kibana 서비스 활성화(부팅 시 자동 시작)  $ sudo systemctl enable kibana.service   3.3.8. Kibana 서비스 비활성화  $ sudo systemctl disable kibana.service   3.3.9. Kibana 서비스 및 관련 프로세스 모두 중지  $ sudo systemctl kill kibana.service   4. Filebeat 설치     Filebeat는 경량 로그 수집기로, SSH 터미널의 사용이 불가능한 상황(로그를 생성하는 서버나 가상 시스템, 컨테이너가 수백~수천 개에 이르는 경우)에 로그와 파일을 경량화된 방식으로 전달하고 중앙 집중화하여 작업을 보다 간편하게 만들어 주는 역할을 합니다.   4.1. apt install 명령어로 Filebeat 설치  $ sudo apt install filebeat -y   4.2. Filebeat 구성  $ sudo vi /etc/filebeat/filebeat.yml   -------------------------------------------------------------------------------- ... - type: log    # Change to true to enable this input configuration.   #enabled: false   enabled: true    # Paths that should be crawled and fetched. Glob based paths.   paths:     #- /var/log/*.log     - /var/log/syslog ... #-------------------------- Elasticsearch output ------------------------------ #output.elasticsearch:   # Array of hosts to connect to.   #hosts: [\"localhost:9200\"]    # Optional protocol and basic auth credentials.   #protocol: \"https\"   #username: \"elastic\"   #password: \"changeme\"  #----------------------------- Logstash output -------------------------------- output.logstash:    #hosts: [\"localhost:5044\"]   hosts: [\"192.168.10.20:5044\"]        # Comment out this line if you are not using SSL on Logstash server   #ssl.certificate_authorities: [\"/etc/pki/root/ca.pem\"]   ssl.certificate_authorities: [\"/etc/ssl/logstash-forwarder.crt\"] ... --------------------------------------------------------------------------------   4.3. systemctl 명령어로 Filebeat 서비스 관리  4.3.1. Filebeat 서비스 설정 반영  $ sudo systemctl daemon-reload   4.3.2. Filebeat 서비스 시작  $ sudo systemctl start filebeat.service   4.3.3. Filebeat 서비스 중지  $ sudo systemctl stop filebeat.service   4.3.4. Filebeat 서비스 재시작  $ sudo systemctl restart filebeat.service   4.3.5. Filebeat 서비스 설정 재적용  $ sudo systemctl reload filebeat.service   4.3.6. Filebeat 서비스 상태 조회  $ sudo systemctl status filebeat.service   4.3.7. Filebeat 서비스 활성화(부팅 시 자동 시작)  $ sudo systemctl enable filebeat.service   4.3.8. Filebeat 서비스 비활성화  $ sudo systemctl disable filebeat.service   4.3.9. Filebeat 서비스 및 관련 프로세스 모두 중지  $ sudo systemctl kill filebeat.service   5. 웹브라우저로 Jenkins 접속     http://[MY-IP]:5601   마무리(CONCLUSION)  Ubuntu 환경에 패키지로 elk 설치를 완료했습니다.   다음 포스트에서는 elk 사용 방법을 소개하겠습니다.   참고(REFERENCES)     https://www.elastic.co/kr/   https://ko.wikipedia.org/wiki/일래스틱서치  ","categories": ["elastic-stack"],
        "tags": ["elastic stack","elk stack","elasticsearch","logstash","kibana","filebeat","ubuntu"],
        "url": "https://lindarex.github.io/elastic-stack/ubuntu-elastic-stack-installation/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 방화벽(UFW) 설정하기",
        "excerpt":"방화벽(UFW, Uncomplicated Firewall, 이하 ufw)은 데비안(이하 debian) 계열 및 다양한 리눅스(이하 linux) 환경에서 작동되고, GPL(GNU General Public License) 라이선스가 적용되며 파이썬(Python)으로 개발되었습니다.   사용하기 쉬운 CLI(command line interface, 명령줄 인터페이스)를 사용하고 프로그램 구성에는 iptables를 사용하는 netfilter 방화벽을 관리하는 프로그램입니다.   ufw는 기본적으로 Ubuntu 18.04 LTS 이후 버전에서 사용할 수 있습니다.   이 포스트에서는 Ubuntu 환경에서 ufw를 설정하는 방법을 소개합니다.   선행조건(PREREQUISITE)     Ubuntu 환경이 필요합니다.      Ubuntu 설치 방법은 VMware workstation에 Ubuntu 16.04 설치하기 또는 VMware workstation에 Ubuntu 18.04 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.3 LTS (Bionic Beaver) Server (64-bit)   요약(SUMMARY)     ufw 활성화 또는 비활성화   ufw 기본 정책(이하 default rules) 조회   ufw default rules 허용 또는 차단   ufw rule 허용 또는 차단   ufw rule 삭제   Service 명으로 ufw rule 허용 또는 차단   IP 주소(이하 IP address)로 ufw rule 허용 또는 차단   ufw ping(icmp) 허용 또는 차단   (선택사항) apt 명령어로 ufw 삭제   내용(CONTENTS)  1. ufw 활성화 또는 비활성화  1.1. ufw 활성화  $ sudo ufw enable      ufw은 기본적으로 비활성화되어 있습니다.    1.2. ufw 비활성화  $ sudo ufw disable   2. ufw 상태 조회  $ sudo ufw status verbose Status: inactive   3. ufw default rules 조회  $ sudo ufw show raw      아래 경로의 하위 파일을 조회하여 확인할 수 있습니다.    $ sudo cat /etc/ufw/user.rules *filter :ufw-user-input - [0:0] :ufw-user-output - [0:0] :ufw-user-forward - [0:0] :ufw-before-logging-input - [0:0] :ufw-before-logging-output - [0:0] :ufw-before-logging-forward - [0:0] :ufw-user-logging-input - [0:0] :ufw-user-logging-output - [0:0] :ufw-user-logging-forward - [0:0] :ufw-after-logging-input - [0:0] :ufw-after-logging-output - [0:0] :ufw-after-logging-forward - [0:0] :ufw-logging-deny - [0:0] :ufw-logging-allow - [0:0] :ufw-user-limit - [0:0] :ufw-user-limit-accept - [0:0] ### RULES ###  ### END RULES ###  ### LOGGING ### -A ufw-after-logging-input -j LOG --log-prefix \"[UFW BLOCK] \" -m limit --limit 3/min --limit-burst 10 -A ufw-after-logging-forward -j LOG --log-prefix \"[UFW BLOCK] \" -m limit --limit 3/min --limit-burst 10 -I ufw-logging-deny -m conntrack --ctstate INVALID -j RETURN -m limit --limit 3/min --limit-burst 10 -A ufw-logging-deny -j LOG --log-prefix \"[UFW BLOCK] \" -m limit --limit 3/min --limit-burst 10 -A ufw-logging-allow -j LOG --log-prefix \"[UFW ALLOW] \" -m limit --limit 3/min --limit-burst 10 ### END LOGGING ###  ### RATE LIMITING ### -A ufw-user-limit -m limit --limit 3/minute -j LOG --log-prefix \"[UFW LIMIT BLOCK] \" -A ufw-user-limit -j REJECT -A ufw-user-limit-accept -j ACCEPT ### END RATE LIMITING ### COMMIT   4. ufw default rules 허용 또는 차단  4.1. ufw default rules 허용  $ sudo ufw default allow   4.2. ufw default rules 차단  $ sudo ufw default deny   5. ufw rule 허용 또는 차단  5.1. TCP 8080 포트(이하 port) 허용  $ sudo ufw allow 8080/tcp   5.2. TCP 8080 port 차단  $ sudo ufw deny 8080/tcp   5.3. UDP 22 port 허용  $ sudo ufw allow 22/udp   5.4. UDP 22 port 차단  $ sudo ufw deny 22/udp   5.5. TCP/UDP 53 port 허용  $ sudo ufw allow 53   5.6. TCP/UDP 53 port 차단  $ sudo ufw deny 53      53 port는 DNS 사용 port입니다.    6. ufw rule 삭제  6.1. TCP 8080 port 차단 rule 삭제  $ sudo ufw delete deny 8080/tcp   6.2. UDP 22 port 차단 rule 삭제  $ sudo ufw delete deny 22/udp   6.3. TCP/UDP 53 port 차단 rule 삭제  $ sudo ufw delete deny 53   7. Service 명으로 ufw rule 허용 또는 차단      아래 명령어로 Service 목록을 조회할 수 있습니다.    $ cat /etc/services      7.1. SSH service 허용  $ sudo ufw allow ssh   7.2. SSH service 차단  $ sudo ufw deny ssh   8. IP address로 ufw rule 허용 또는 차단  8.1. IP address 허용  $ sudo ufw allow from 192.168.10.20   8.2. IP address 차단  $ sudo ufw deny from 192.168.10.20   8.3. IP address subnet(net mask) 허용  $ sudo ufw allow from 192.168.10.0/24   8.4. IP address subnet(net mask) 차단  $ sudo ufw deny from 192.168.10.0/24   8.5. IP address와 port 허용  $ sudo ufw allow from 192.168.10.20 to any port 22   8.6. IP address와 port 차단  $ sudo ufw deny from 192.168.10.20 to any port 22   8.7. IP address와 port, protocol 허용  $ sudo ufw allow from 192.168.10.20 to any port 22 proto tcp   8.8. IP address와 port, protocol 차단  $ sudo ufw deny from 192.168.10.20 to any port 22 proto tcp   9. ufw ping(icmp) 허용 또는 차단      ufw는 기본적으로 ping 요청을 허용합니다.    9.1. ufw ping(icmp) 허용  $ sudo vi /etc/ufw/before.rules   ... # ok icmp codes -A ufw-before-input -p icmp --icmp-type destination-unreachable -j ACCEPT -A ufw-before-input -p icmp --icmp-type source-quench -j ACCEPT -A ufw-before-input -p icmp --icmp-type time-exceeded -j ACCEPT -A ufw-before-input -p icmp --icmp-type parameter-problem -j ACCEPT -A ufw-before-input -p icmp --icmp-type echo-request -j ACCEPT ...   9.2. ufw ping(icmp) 차단  $ sudo vi /etc/ufw/before.rules   ... # ok icmp codes -A ufw-before-input -p icmp --icmp-type destination-unreachable -j DROP -A ufw-before-input -p icmp --icmp-type source-quench -j DROP -A ufw-before-input -p icmp --icmp-type time-exceeded -j DROP -A ufw-before-input -p icmp --icmp-type parameter-problem -j DROP -A ufw-before-input -p icmp --icmp-type echo-request -j DROP ...      ‘ACCEPT’를 ‘DROP’으로 변경합니다.    10. (선택사항) apt 명령어로 ufw 삭제     설정 파일을 유지하며 ufw를 삭제합니다.   $ sudo apt remove ufw $ sudo apt remove --auto-remove ufw      설정 파일과 함께 ufw를 삭제합니다. (단, 사용자 홈 디렉터리의 설정 파일은 유지됩니다.)     $ sudo apt purge ufw $ sudo apt purge --auto-remove ufw           마무리(CONCLUSION)  Ubuntu 환경에 ufw 설정을 완료했습니다.   다음 포스트에서는 Iptables 방화벽 특징과 설정 방법을 소개하겠습니다.   참고(REFERENCES)     https://help.ubuntu.com/community/UFW   http://manpages.ubuntu.com/manpages/bionic/en/man8/ufw.8.html  ","categories": ["ubuntu"],
        "tags": ["ufw","ubuntu"],
        "url": "https://lindarex.github.io/ubuntu/ubuntu-ufw-setting/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "클라우드 파운드리(Cloud Foundry, CFAR) 소개",
        "excerpt":"클라우드 파운드리(이하 Cloud Foundry)는 과거에 PaaS(Platform as a Service)와 재단을 가리키는 용어였지만, 현재는 PaaS를 뜻하는 Cloud Foundry는 CFAR(cloud foundry application runtime)로 대체되었습니다.   CFAR은 개방형 기여(contribution) 및 개방형 거버넌스 모델(governance model)을 갖춘 Apache License 2.0으로 배포된 오픈소스 클라우드 애플리케이션 플랫폼(open source cloud application platform)입니다.   사용자가 업체(vendor)에 종속되지 않도록 유연성을 제공하고, 애플리케이션(이하 application)을 더 빠르고 쉽게 구축(이하 build)하여 테스트(이하 test)하고 배포(이하 deploy)하며 확장할 수 있는 기능을 제공합니다.   이 포스트에서는 CFAR을 소개합니다.   내용(CONTENTS)     CFAR은 클라우드(IaaS) 환경, 개발 프레임워크(Buildpack) 및 application 서비스(Service)를 선택할 수 있으며, application을 빠르고 쉽게 build, test하고 deploy 하며 확장할 수 있는 오픈소스(이하 open source) 멀티 클라우드(이하 cloud) application PaaS입니다.   CFAR의 컨테이너(이하 container) 기반 아키텍처는 아마존 웹 서비스(AWS), 마이크로소프트 애저(Azure), 구글 컴퓨트 플랫폼(GCP), 오픈스택(OpenStack), VM웨어(VMware) vSphere 등의 다양한 cloud 환경 위에서 다양한 언어로 application을 실행할 수 있도록 합니다.   CFAR은 초기 개발부터 test, 그리고 deploy에 이르는 완전한 application 수명 주기(lifecycle)를 지원하기 때문에 지속적 배포(CD, continuous delivery)에 적합합니다.   CFAR은 루비(Ruby), 고언어(Go), 자바(Java)로 개발되었으며, BOSH deployment 스크립트(이하 script)를 이용하여 IaaS에 deploy 합니다.      국내에서는 한국정보화진흥원(NIA, National Information Society Agency)에서 2014년부터 CFAR을 이용한 PaaS 아키텍처와 기능 분석을 시작했고, 2016년에 CFAR과 개발 도구 및 운영 도구를 패키징한 PaaS-TA라는 open source PaaS 플랫폼(이하 platform)을 공개했습니다. 2016년에 버전 1.0을 시작으로 다양한 서비스(이하 service)와 버전 업그레이드를 통해 코스콤, KT, LG CNS, SK 등 민간 기업과 협력하면서 2019년에 버전 5.0까지 배포되었습니다.       open source project인 CFAR을 상용화한 Pivotal Cloud Foundry(PCF)와 IBM Cloud(IBM Bluemix) 등은 전 세계적으로 TOP 10 안에 드는 PaaS platform이며, Public, Private 또는 하이브리드(Hybrid) IaaS 환경에서 모두 활용 가능합니다.       IaaS(Infrastructure as a Service)란 서버 자원, 네트워크(network), 스토리지(storage) 등 인프라(이하 infra) 자원(resources)을 쉽고 편하게 이용할 수 있는 cloud service 형태로 제공하는 것을 의미하며, PaaS와 SaaS(Software as a Service)의 기반입니다.  서버 가상화, 데스크톱 가상화 등의 기술로 구현되며, 대표적으로 AWS EC2(Elastic Cloud Compute), MS Azure, Google compute engine, OpenStack 등이 있습니다.       PaaS란 Platform as a Service의 약자로 application 개발을 위한 infra를 구축하고 유지보수하는 복잡함 없이, application을 개발하고 실행 및 관리할 있는 platform을 제공하는 service를 의미합니다.  대표적인 상용 PaaS로는 Pivotal Cloud Foundry, Google App Engine, Oracle Cloud Platform, Heroku 등이 있습니다.       SaaS는 cloud 환경에서 동작하는 application을 service 형태로 제공하는 것으로 Software as a Service의 약자입니다.  주문형 소프트웨어(on-demand software)라고도 하며, 대표적으로 Google Gmail, Google docs, Dropbox 등이 있습니다.       Buildpack이란 application을 CFAR로 배포(이하 push)할 때, application에 대한 프레임워크(이하 framework) 및 런타임(이하 runtime) 지원을 제공합니다. CFAR은 push 되는 application을 검사하여 적합한 buildpack을 감지하고, 이 buildpack은 내려받을 종속성(dependencies)을 결정하고 바인딩(이하 binding) 된 service와 통신하도록 application 구성을 설정합니다. buildpack에 대한 자세한 정보는 https://docs.cloudfoundry.org/buildpacks/를 확인해 주시기 바랍니다.       바인딩(Binding)이란 일반적으로 하나를 다른 것으로 매핑시키는 것을 의미합니다. Cloud Foundry에서 binding은 service instance를 push 된 application에 연결 또는 연관(association)시키는 것이며, 반대는 unbinding입니다.    1. 역사(history)     CFAR은 VMware에 의해 개발되어 Pivotal Software로 넘어간 후, 2015년 1월에 Cloud Foundry 재단이 비영리 독립 리눅스 재단 협업 project의 하나로 설립되어, Cloud Foundry 소프트웨어(소스 코드 및 모든 관련 상표)는 open source 소프트웨어 재단의 소유가 되었습니다.   현재 CFAR 개발은 Cloud Foundry 재단이 관리 및 통제하고 있습니다.   2. 아키텍처(architecture)     3. 지원되는 런타임 및 프레임워크(runtimes and frameworks)  |언어(language)|런타임(runtimes)|프레임워크(frameworks)| |—|—|—| |자바(Java)|Java 6 ~ 8\t|스프링 프레임워크(Spring Frameworks) 3.x, 4.x| |루비(Ruby)|Ruby 1.8 ~ 2.2|레일즈(Rails), Sinatra| |Node.js|V8 자바스크립트 엔진 (구글 크롬)|Node.js| |스칼라(Scala)|Scala 2.x\t|플레이(play) 2.x, 리프트(lift)| |파이썬(Python)|Python 2.7.10 ~ 3.5.1|Python| |PHP|PHP 5.5 ~ 7.0|PHP| |Go|Go 1.1.1 ~ 1.4.2|Go|      출처 :: https://ko.wikipedia.org/w/index.php?title=클라우드_파운드리&amp;action=edit&amp;section=4    4. 구성요소(component)     각 구성요소에 대한 최신 배포(release) 버전과 저장소(이하 repository), 개별 설치 방법은 생략합니다.   4.1. Router     라우터(이하 router)는 들어오는 트래픽을 클라우드 컨트롤러(Cloud Controller) 컴포넌트(이하 component) 또는 디에고 셀(Diego Cell)에서 실행되는 호스팅 된 application으로 라우팅합니다.   router는 주기적으로 Diego Bulletin Board System(BBS)을 조회하여 현재 application이 실행 중인 셀(이하 cell)과 container를 결정하고, 이 정보로 각 cell 가상 머신(virtual machine, 이하 VM)의 IP 주소(address)와 cell container의 호스트 측 포트(port) 번호를 기반으로 새로운 라우팅 테이블을 다시 계산합니다.      router에 대한 자세한 정보는 https://docs.cloudfoundry.org/concepts/architecture/router.html을 확인해 주시기 바랍니다.    4.2. OAuth2 UAA server     OAuth2 UAA(User Account and Authentication) 서버(이하 server)와 로그인(이하 login) server는 함께 작동하여 ID 관리 기능을 제공합니다.   UAA는 OAuth2 제공자(이하 provider)로서 CFAR 사용자를 대신하여 클라이언트(이하 client) application이 사용할 수 있는 토큰(token)을 발행합니다.   UAA는 login server와 연동하여 CFAR 자격 증명(credentials)으로 사용자를 인증 할 수 있으며, 이러한 자격 증명이나 다른 자격 증명을 사용하여 SSO service를 제공할 수 있습니다.   UAA에는 사용자 계정을 관리하고 OAuth2 client를 등록하기 위한 엔드 포인트(이하 endpoints)와 다양한 관리 기능이 있습니다.   CFAR에는 기본적으로 두 개의 UAA 인스턴스(이하 instance)가 있는데, 하나는 BOSH Director 용이며 다른 하나는 BOSH 배포(CFAR도 BOSH 배포에 포함) 용도로 사용됩니다.   하나의 runtime 또는 service에 login 하면, UAA를 사용하여 인증하는 다른 runtime 및 service에는 login 되지 않고, 각 runtime 또는 service에 별도로 login 해야 합니다.      UAA에 대한 자세한 정보는 https://docs.cloudfoundry.org/concepts/architecture/uaa.html을 확인해 주시기 바랍니다.    4.3. Cloud Controller     클라우드 컨트롤러(Cloud Controller, 이하 CC)는 application push를 지시합니다.   application을 CFAR로 push 하기 위해 CC를 대상(target)으로 하고, CC-Bridge components를 통해 Diego Brain에 지시하여 개별 Diego Cell을 조정한 후, application을 준비(stage)하고 실행합니다.   CC는 client가 시스템에 접근할 수 있도록 REST API endpoints를 제공하고, 조직(orgs), 공간(spaces), 서비스(services), 사용자 역할(user roles) 등의 데이터베이스(이하 database)를 유지하고 관리합니다.      CC에 대한 자세한 정보는 https://docs.cloudfoundry.org/concepts/architecture/cloud-controller.html을 확인해 주시기 바랍니다.       Diego cell에 대한 자세한 정보는 https://docs.cloudfoundry.org/concepts/architecture/#diego-cell을 확인해 주시기 바랍니다.    4.4. Blobstore     Blobstore는 큰 바이너리(이하 binary) 파일(이하 file)을 저장할 수 있는 repository입니다.   application code packages, buildpacks, droplets를 포함하고 있으며, 내부 server 또는 외부 S3 또는 S3 호환 endpoints로 구성할 수 있습니다.      droplets이란 application을 CFAR로 push하고 buildpack을 사용하여 deploy 하면 생성되는 CFAR의 실행 단위입니다.    4.5. Diego Cell     application instances와 application tasks, staging tasks는 모두 Diego Cell VM에서 Garden container로 실행됩니다.   Diego cell rep component는 container의 lifecycle과 container에서 실행되는 프로세스(process)를 관리하고, container 상태를 Diego BBS에 보고하며, 로그(이하 log)와 측정지표(이하 metrics)를 Loggregator로 보냅니다.      Garden에 대한 자세한 정보는 https://docs.cloudfoundry.org/concepts/architecture/garden.html을 확인해 주시기 바랍니다.    4.6. Service Brokers     application은 database나 third-party SaaS provider와 같은 service에 의존하는데, service를 프로비저닝(provisioning)하고 application에 binding 할 경우, 해당 service의 service broker는 service instance를 제공하는 역할을 수행합니다.      프로비저닝(Provisioning)이란 사용자의 요구에 맞게 시스템 자원을 할당하고 배치하여 배포해 두었다가, 필요할 때 시스템을 즉시 사용할 수 있는 상태로 미리 준비해 두는 것을 의미합니다.       CFAR의 service에 대한 자세한 정보는 http://docs.cloudfoundry.org/services/index.html을 확인해 주시기 바랍니다.    4.7. Internal networking     CFAR component VM은 HTTP와 HTTPS 프로토콜(이하 protocol)을 통해 내부적으로 서로 통신하며, Diego의 Bulletin Board System(BBS)에 저장된 임시 메시지(이하 message)와 데이터(이하 data)를 공유합니다.   BOSH Director는 deploy 된 모든 VM에 BOSH DNS server를 설치하고, 모든 VM은 다른 모든 VM에 대한 최신 DNS 레코드(record)를 같은 기반으로 유지하여 VM 간의 service 검색을 가능하게 합니다.   BOSH DNS는 여러 VM을 사용할 수 있을 때, 상태가 양호한 VM을 임의로 선택하여 client 측 로드 밸런싱(load balancing)을 제공합니다.   route-emitter component는 NATS protocol을 사용하여 최신 라우팅 테이블을 router로 전송합니다.   Diego BBS는 cell과 application 상태, 할당되지 않은 작업, heartbeat messages 등과 같이 자주 업데이트되는 data와 일회성 data, 수명이 긴 distributed locks를 저장하며, Go MySQL 드라이버를 사용하여 MySQL에 data를 저장합니다.      Bulletin Board System(BBS)에 대한 자세한 정보는 https://docs.cloudfoundry.org/concepts/diego/diego-architecture.html#bbs를 확인해 주시기 바랍니다.       BOSH DNS에 대한 자세한 정보는 https://bosh.io/docs/dns/를 확인해 주시기 바랍니다.    4.8. Loggregator     Loggregator(log aggregator) system은 application log를 스트리밍하여 개발자에게 전송합니다.      Loggregator에 대한 자세한 정보는 https://docs.cloudfoundry.org/loggregator/architecture.html을 확인해 주시기 바랍니다.    4.9. Metrics Collector     Metrics Collector는 component로부터 metrics와 통계치(statistics)를 수집하고, 운영자는 이 정보를 사용하여 Cloud Foundry deployment를 모니터링할 수 있습니다.   마무리(CONCLUSION)  CFAR에 대한 소개와 architecture, component 등을 살펴보았습니다.   CFAR을 비롯해서 Cloud, PaaS, IaaS, SaaS 등의 기술 트랜드는 선택이 아닌 필수가 되었습니다. 대기업 및 금융권 등 현업에서는 Cloud 전환 프로젝트가 빠르게 진행 중이고, 공공 기관에서도 위에 소개한 PaaS-TA를 이용한 다양한 과제가 진행되고 있습니다. CFAR에 대한 더 자세한 내용은 앞으로 다양한 포스트로 소개할 예정입니다.   다음 포스트에서는 Cloud Foundry projects를 소개하겠습니다.   참고(REFERENCES)     https://www.cloudfoundry.org/   https://docs.cloudfoundry.org/concepts/architecture/   https://ko.wikipedia.org/wiki/클라우드_파운드리   http://www.ciokorea.com/news/37345   https://www.trustradius.com/platform-as-a-service-paas   https://www.updatedreviews.in/top-10-best-paas-providers   https://www.slant.co/topics/3478/~best-platform-as-a-service-providers-that-have-a-free-plan   https://www.devteam.space/blog/10-top-paas-providers/   ","categories": ["cfar"],
        "tags": ["cloud foundry","cfar","paas"],
        "url": "https://lindarex.github.io/cfar/cfar-introduction/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "클라우드 파운드리(Cloud Foundry) 프로젝트(projects) 소개",
        "excerpt":"이 포스트에서는 클라우드 파운드리(이하 Cloud Foundry) 프로젝트(이하 projects)를 간단히 소개합니다.   내용(CONTENTS)  1. BOSH     BOSH는 복잡한 분산 시스템의 release engineering, 배포(이하 deploy) 및 애플리케이션(이하 application) 수명 주기(이하 lifecycle) 관리를 위한 클라우드(이하 cloud) 오픈소스(open source) 소프트웨어입니다.   BOSH는 가상 머신(Virtual machine, 이하 VM)이나 컨테이너(이하 container), 베어 메탈(bare metal) 등 어디에 deploy 하든 상관없이 동일한 접근 방식을 취하고, 대부분의 application을 deploy 할 때 BOSH가 사용됩니다.   BOSH는 백그라운드에서 작동하며, 구성요소(component)가 변경될 때, application을 최신 상태로 유지하고, 환경이 올바르게 구성되었는지 확인하여 환경이 정의되었을 때 실행 방식을 조정하도록 재구성합니다.   BOSH는 스템셀(이하 stemcell), 릴리스(이하 release) 및 배포 매니페스트(이하 deployment manifest)를 사용하여 cloud 환경의 무결성(integrity)을 유지합니다.            stemcell                    VM을 생성하는 데 사용되는 골든 운영체제 이미지(golden operating system image)와 유사합니다.           배포에 포함된 기본 운영체제(Operating system, OS)를 다른 application 패키지(package)와 분리합니다.                       release                    stemcell 위에 놓인 레이어(layer)로 어떤 application을 deploy하고 어떻게 구성해야 하는지 BOSH에 application을 패키지화하여 전달합니다.           release는 구성 속성(configuration properties) 및 템플릿(templates), 시작(startup) scripts, 소스 코드(source code), 바이너리(binary) 아티팩트(artifacts)를 포함하며, 재현 가능한 방식(reproducible)으로 application을 build하고 deploy 하는 데 필요한 모든 것이 포함됩니다.                       deployment manifest                    어떤 cloud 또는 인프라(이하 infra)에 어떤 BOSH release를 deploy하고, 어떻게 구성해야 하는지 설명하는 yaml file입니다.           BOSH는 manifest file을 사용하여 대상 infra에 deploy하고, VM 또는 container의 상태를 모니터링하고, 필요시에 복구합니다.                           BOSH는 CPI(Cloud Provider Interface) 모델(이하 model)을 포함하며, 이는 멀티(이하 multi) cloud 기능(capability)의 핵심입니다.   BOSH는 CPI를 사용하여 AWS, Azure, GCP, OpenStack, VMware vSphere 등을 포함한 여러 cloud 환경에 application을 deploy 할 수 있습니다.   CPI는 BOSH가 infra와 상호 작용하여 stemcell, VM 및 디스크(disk)를 생성하고 관리하는 데 사용하는 API입니다.   BOSH는 초기에 CFAR을 배포하기 위해 생성되었지만, 현재는 다른 환경에서 모든 종류의 application을 package하고 관리하기 위해 사용되고 있습니다.      Bare metal이란 소프트웨어가 설치되어 있지 않은 단일 테넌트(single-tenant) 물리적 하드웨어를 의미하며, 가상화 및 cloud 호스팅(이하 hosting)과 구별하기 위해 사용됩니다. bare metal에 대한 자세한 정보는 https://en.wikipedia.org/wiki/Bare-metal_server를 확인해 주시기 바랍니다.    2. CFAR(cloud foundry application runtime)     CFAR은 클라우드 환경과 개발 프레임워크, application 서비스를 선택할 수 있으며, application을 빠르고 쉽게 구축하고 테스트하여 deploy 할 수 있는, 완전한 application lifecycle을 지원하는 open source multi cloud application PaaS(Platform as a Service)입니다.      CFAR에 대한 자세한 설명은 클라우드 파운드리(Cloud Foundry, CFAR) 소개 포스트를 참고하시기 바랍니다.    3. CFCR(cloud foundry container runtime)     CFCR은 kubernetes를 사용하여 container를 더 세밀하게 제어하고 관리할 수 ​​있는 기능을 제공합니다.   CFCR은 과거에 Cloud Foundry Foundation 내의 incubating project인 Project Kubo였는데, container platform의 성장과 함께 container runtime인 kubo를 CFCR로 명칭을 변경했습니다.   CFCR은 2017년 11월에 kubernetes 적합성 인증(Certified Kubernetes)을 받았고, BOSH를 사용하여 cloud platform에서 고가용성(이하 high availability)의 kubernetes 클러스터(이하 cluster)를 인스턴스화하고 deploy 및 관리할 수 있는 기능을 제공합니다.   kubernetes와 BOSH의 조합으로 BOSH를 통해 deploy 및 lifecycle를 관리하면, kubernetes cluster의 high availability 및 스케일링(scaling), VM healing 그리고 롤링 업그레이드(rolling upgrade)를 할 수 있습니다.      Certified Kubernetes란 CNCF(Cloud Native Computing Foundation)의 Kubernetes Software Conformance Certification Program으로 kubernetes의 목표인 일관성과 휴대성을 위한 검토와 인증에 대한 적합성 시험 결과를 CNCF로 제출하여, CNCF로부터 준수 구현을 공식적으로 인증받은 것을 의미합니다. Certified Kubernetes에 대한 자세한 정보는 https://www.cncf.io/certification/software-conformance/를 확인해 주시기 바랍니다.    4. Quarks     Project Quarks(이하 quarks)는 Cloud Foundry Foundation 내의 incubating project로, CFAR을 VM 대신 container로 패키징하여 kubernetes에 쉽게 deploy 할 수 있는 기능을 제공합니다.   container형 CFAR은 BOSH로 deploy 한 CFAR과 동일한 기능을 제공하고, 더 적은 infra 용량으로 kubernetes 운영자에게 익숙한 환경을 제공합니다.   quarks는 기존 BOSH release를 kubernetes에 설치하기 위해 docker 이미지(이하 image) 또는 Helm Charts로 변환합니다.   kubernetes는 CFAR instance의 자동 확장 및 실패한 노드(node)를 복구하는 기능을 제공합니다.   kubernetes를 기본 infra로 사용하면 quarks를 모든 Private 또는 Public cloud에 쉽게 deploy 할 수 있습니다.      Helm은 Kubernetes의 package 관리자이며, Helm을 사용하면 application 및 리소스(resources)를 Kubernetes cluster에 쉽게 설치할 수 있습니다. Helm Charts는 Kubernetes resources 세트를 Kubernetes cluster에 설치하기 위한 Helm 패키지이며, Helm Charts에는 Chart.yaml, templates, values.yaml 및 의존성(dependencies)이 포함됩니다. Helm에 대한 자세한 정보는 https://helm.sh/를 확인해 주시기 바랍니다.    5. Eirini     Project Eirini(이하 eirini)는 Cloud Foundry Foundation 내의 incubating project로, CFAR을 위한 플러그형 스케줄링을 가능하게 하며 application container instance를 조정하기 위해 Diego/Garden 또는 Kubernetes 중에서 선택할 수 있습니다.   eirini는 기존 Kubernetes cluster infra를 재사용하여 CFAR에 의해 deploy 된 application을 hosting 합니다.   개발자가 buildpack을 사용하여 application을 push 하면, kubernetes 내부에서 일회성 스테이징 작업이 포드(pod)로 실행되고, 드롭릿(droplet)이 동일한 방식으로 생성하여 업로드됩니다. 이 과정에서 application은 docker image로 다운로드되어 kubernetes에 deploy 됩니다.   eirini는 CFAR 운영자가 kubernetes를 container 스케줄러로 선택할 수 있도록 하여, kubernetes에 익숙한 조직이 CFAR을 보다 쉽게 이용할 수 있도록 합니다.   6. Open Service Broker API     Open Service Broker API project를 통해 독립적인 application vendor와 SaaS provider는 CFAR과 kubernetes와 같은 cloud native platform에서 실행되는 워크로드(이하 workload)에 대한 백 앤드 서비스를 쉽게 제공할 수 있습니다.   Open Service Broker API는 많은 platform과 service provider가 채택하였고, Google, IBM, Pivotal, Red Hat, SAP 등 다수의 cloud 회사들이 기여했습니다.   Open Service Broker API 사양의 service broker는 service lifecycle을 관리하고, platform은 service broker와 상호 작용하여 service를 provisioning, access, 관리합니다.   마무리(CONCLUSION)  Cloud Foundry projects를 살펴보았습니다.   BOSH는 Cloud Foundry projects에 기반이 되는 프로젝트이고, CFAR을 제외한 나머지 CFCR, Quarks, Eirini 등의 공통 키워드는 Kubernetes입니다. 더 말이 필요 없는 kubernetes…   다음 포스트에서는 kubernetes 소개와 CFAR을 설치하는 방법을 소개하겠습니다.   참고(REFERENCES)     https://www.cloudfoundry.org/   https://www.cncf.io/   https://github.com/cncf/k8s-conformance  ","categories": ["concepts"],
        "tags": ["cloud foundry","cfar","cfcr","bosh","quarks","eirini","kubernetes","paas"],
        "url": "https://lindarex.github.io/concepts/cloud-foundry-projects-introduction/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"},{
        "title": "우분투(Ubuntu) 환경에 iptables 설정하기",
        "excerpt":"iptables은 방화벽(이하 firewall) 구성이나 NAT(network address translation)에 사용되는데, 시스템 관리자가 리눅스(이하 linux) 커널(이하 kernel) 방화벽이 제공하는 테이블(이하 table)과 체인(이하 chain), 규칙(이하 rule)으로 구성합니다.   각각 다른 kernel 모듈(이하 module)과 프로그램들은 다른 프로토콜(이하 protocol)을 위해 사용되는데, iptables는 IPv4에, ip6tables는 IPv6에, arptables는 ARP에, ebtables는 이더넷(ethernet) 프레임에 적용됩니다.   linux 시스템(이하 system)에서 iptables는 /usr/sbin/iptables에 설치되며, iptables의 후속 버전은 nftables입니다.   이 포스트에서는 Ubuntu 환경에서 iptables를 설정하는 방법을 소개합니다.      nftables이란 iptables에 비해 코드 중복이 적고 처리량이 더 많은 iptables의 후속 버전이며, linux kernel 3.13부터 사용 가능합니다. nftables에 대한 자세한 정보는 https://en.wikipedia.org/wiki/Nftables를 확인해 주시기 바랍니다.    선행조건(PREREQUISITE)     Ubuntu 환경이 필요합니다.      Ubuntu 설치 방법은 VMware workstation에 Ubuntu 16.04 설치하기 또는 VMware workstation에 Ubuntu 18.04 설치하기 포스트를 참고하시기 바랍니다.    테스트 환경(TEST ENVIRONMENT)     VMware® Workstation 15 Pro (15.5.1 build-15018445)   Ubuntu 18.04.4 LTS (Bionic Beaver) Server (64-bit)   요약(SUMMARY)     iptables 확인 및 초기화   iptables 조회   iptables 용어   iptables 사용 방법   내용(CONTENTS)     iptables는 kernel 2.4 이전 버전에서 사용되던 ipchains를 대신하는 firewall 도구이며, NetFilter 프로젝트에서 개발했습니다.   iptables는 kernel에서 netfilter 패킷(이하 packet) 필터링(이하 filtering) 기능을 사용자 공간에서 제어하는 수준으로 사용하고, protocol 상태 추적, packet 애플리케이션(이하 application) 계층(layer) 검사, 속도 제한, filtering 정책(이하 policy) 등의 기능을 제공합니다.   Ubuntu 18.04는 기본적으로 iptables와 함께 UFW(Uncomplicated Firewall, 이하 ufw)를 제공합니다.   iptables를 설정하기 전에 ufw를 비활성화하거나 제거하는 것을 추천합니다.   iptables 설정에는 ROOT 권한을 요구하기 때문에, 이 포스트에서는 ROOT 사용자가 설정한다는 가정하에 설명합니다.      ufw에 대한 자세한 설명은 우분투(Ubuntu) 환경에 방화벽(UFW) 설정하기 포스트를 참고하시기 바랍니다.    1. iptables 확인 및 초기화     ROOT 권한 필요    1.1. iptables 확인  # which iptables /sbin/iptables   # iptables -V iptables v1.6.1   1.2. iptables 초기화     모든 chain에 설정된 모든 rule을 제거합니다.   # iptables -F      기본 chain을 제외한 나머지 모든 chain에 설정된 모든 rule을 제거합니다.   # iptables -X   2. iptables 조회     아래 명령어의 결과는 iptables의 기본 설정 상태입니다.       기본 조회입니다.   # iptables -L chain INPUT (policy ACCEPT) target     prot opt source               destination  chain FORWARD (policy ACCEPT) target     prot opt source               destination  chain OUTPUT (policy ACCEPT) target     prot opt source               destination      아래는 조회에 사용되는 ‘-L’ command의 옵션 목록입니다.            ‘-v’ 또는 ‘–verbose’ :: 각 chain의 packet과 byte counters 정보, 각 rule에 일치하는 packet과 byte counters 정보 및 특정 rule에 적용되는 인터페이스(이하 interface) 등을 조회합니다.       ‘-n’ 또는 ‘–numeric’ :: 기본 호스트(이하 host) 이름, 네트워크(이하 network) 이름 또는 서비스(이하 service) 형식이 아닌 IP 주소(이하 address)와 포트(이하 port) 번호(이하 number)로 표시합니다.       ‘-x’ 또는 ‘–exact’ :: packet과 byte counters 정보를 정확한 값으로 확장하여 표시합니다.       ’–line-numbers’ :: chain의 각 rule의 시작 부분에 숫자를 추가합니다.           상세 조회입니다.   # iptables -L -v Chain INPUT (policy ACCEPT 10 packets, 676 bytes)  pkts bytes target     prot opt in     out     source               destination  Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)  pkts bytes target     prot opt in     out     source               destination  Chain OUTPUT (policy ACCEPT 5 packets, 812 bytes)  pkts bytes target     prot opt in     out     source               destination      IP address와 port number로 표시하여 조회합니다.   # iptables -L -n Chain INPUT (policy ACCEPT) target     prot opt source               destination  Chain FORWARD (policy ACCEPT) target     prot opt source               destination  Chain OUTPUT (policy ACCEPT) target     prot opt source               destination      정확한 값으로 확장하여 조회합니다.   # iptables -L -x Chain INPUT (policy ACCEPT) target     prot opt source               destination  Chain FORWARD (policy ACCEPT) target     prot opt source               destination  Chain OUTPUT (policy ACCEPT) target     prot opt source               destination      rule의 시작 부분에 숫자를 추가하여 조회합니다.   # iptables -L --line-numbers Chain INPUT (policy ACCEPT) num  target     prot opt source               destination  Chain FORWARD (policy ACCEPT) num  target     prot opt source               destination  Chain OUTPUT (policy ACCEPT) num  target     prot opt source               destination      전체 rule을 출력합니다.   # iptables -S -P INPUT ACCEPT -P FORWARD ACCEPT -P OUTPUT ACCEPT      전체 rule을 상세하게 출력합니다.   # iptables -S -v -P INPUT ACCEPT -c 117 8240 -P FORWARD ACCEPT -c 0 0 -P OUTPUT ACCEPT -c 103 13208      ‘-L’과 ‘-S’ 옵션의 차이점은 설명으로는 조회와 출력이 차이지만, 산출 형식(output format)이 다릅니다. ‘-L’ 옵션은 reference, 즉 참조용이지만, ‘-S’ 옵션은 reusable output, 즉 재사용을 위한 출력입니다. ‘-S’ 옵션은 iptables-save 방식으로 생성되어 iptables-apply 및 iptables-restore에 다시 사용할 수 있습니다.    3. iptables 용어  3.1. target     target은 packet이 rule과 일치할 때 실행될 명령입니다.   각각의 target에 대한 설명은 아래와 같습니다.            ACCEPT :: packet을 허용합니다.       DROP :: packet을 차단하고, 사용자에게 오류 메시지를 보내지 않습니다.       REJECT :: packet을 차단하고, 사용자에게 오류 메시지를 보냅니다.       LOG :: packet을 syslog에 기록합니다.       RETURN :: chain 통과를 중지하고, 이전(호출) chain의 다음 rule에 따라 다시 시작합니다.       QUEUE :: application에 packet을 대기(queue)시키는 데 사용합니다.       SNAT :: 소스 네트워크 주소 변환(source network address translation)에 사용되며, 이는 packet의 IP 헤더에 source IP address를 다시 쓰는 데 사용됩니다.       DNAT :: 대상 네트워크 주소 변환(destination network address translation)에 사용되며, 이는 packet의 destination IP address를 다시 쓰는 데 사용됩니다.           3.2. chain     chain은 순차적으로 검사하는 rule 세트이며, packet이 rule 중 하나와 일치하면 관련 작업이 실행되고, chain의 나머지 rule은 확인하지 않습니다.   filter table에는 미리 정의된 INPUT, FORWARD, OUTPUT 등 3개의 chain이 존재하며, 그 외에 PREROUTING, POSTROUTING 등 2개의 chain이 존재합니다.   INPUT, FORWARD, OUTPUT chain은 기본 chain으로 삭제가 안 되고 영구적으로 사용되며, ‘-N’ 옵션으로 사용자가 chain을 구성하여 사용할 수 있습니다.   chain은 network 통신(IP packet)에 미리 설정한 rule을 적용하여 target을 결정합니다.   각각의 chain에 대한 설명은 아래와 같습니다.            INPUT :: system으로 들어오는 packet의 policy rules입니다.       OUTPUT :: system에서 나가는 packet의 policy rules입니다.       FORWARD :: system에서 다른 system으로 보내는 packet의 policy rules입니다.       PREROUTING :: packet이 INPUT chain에 도달하기 전에 packet을 변경합니다.       POSTROUTING :: packet이 OUTPUT chain을 종료한 후에 packet을 변경합니다.           3.3. table     iptables는 filter, nat, mangle, raw, security 등 5개의 table이 존재합니다.        ‘-t’ 또는 ‘–table’ 옵션으로 packet matching table을 지정합니다.       filter table            기본 table이며, ‘-t’ 옵션이 없을 때 적용합니다.       filter table은 built-in chain INPUT, FORWARD, OUTPUT으로 구성됩니다.           nat table            nat table은 새로운 연결을 생성하는 packet이 발견되면 참조됩니다.       nat table은 built-in chain PREROUTING, INPUT, OUTPUT, POSTROUTING으로 구성됩니다.       IPv6 NAT는 kernel 3.7부터 지원합니다.           mangle table            mangle table은 특수한 packet 변경에 사용됩니다.       mangle table은 kernel 2.4.17까지 built-in chain PREROUTING, OUTPUT으로 구성되었다가, kernel 2.4.18부터 built-in chain INPUT, FORWARD, POSTROUTING도 추가 구성되었습니다.           raw table            raw table은 NOTRACK 대상과 함께 연결 추적의 제외 구성 시에 사용됩니다.       raw table은 built-in chain PREROUTING, OUTPUT으로 구성됩니다.           security table            security table은 SELinux와 같은 linux 보안 module에 의해 구현되는 Mandatory Access Control(이하 MAC) 네트워킹 rule에 사용됩니다.       security table은 filter table 다음에 호출되기 때문에, security table MAC rule이므로 filter table의 Discretionary Access Control(DAC)보다 나중에 적용됩니다.       security table은 built-in chain INPUT, FORWARD, OUTPUT으로 구성됩니다.           3.4. parameter     iptables의 rule 스펙(specification)을 구성하며, add, delete, insert, replace 및 append 명령어에 사용됩니다.   각각의 parameter에 대한 설명은 아래와 같습니다.            ‘-4’ 또는 ‘–ipv4’ :: iptables 및 iptables-restore에 영향이 없고, 단일 rule 파일(이하 file)에서 iptables-restore 및 ip6tables-restore와 함께 사용하여 IPv4 및 IPv6 rule을 허용합니다.       ‘-6’ 또는 ‘–ipv6’ :: ip6tables 및 ip6tables-restore에 영향이 없고, 단일 rule 파일(이하 file)에서 iptables-restore 및 ip6tables-restore와 함께 사용하여 IPv4 및 IPv6 rule을 허용합니다.       ‘-p’ 또는 ‘–protocol’ :: rule 또는 packet의 protocol을 확인합니다.       ‘-s’ 또는 ‘–source’ :: 출발지 network 이름, host 이름, network IP address(/mask) 또는 일반 IP address를 확인합니다.       ‘-d’ 또는 ‘–destination’ :: 목적지 network 이름, host 이름, network IP address(/mask) 또는 일반 IP address를 확인히며, 별칭(alias)은 ‘-dst’입니다.       ‘-m’ 또는 ‘–match’ :: 사용할 확장 패킷 모듈(extended packet modules)을 지정합니다.       ‘-j’ 또는 ‘–jump’ :: rule의 target을 지정합니다.       ‘-g’ 또는 ‘–goto’ :: 사용자 지정 chain으로 계속 처리되도록 명시합니다.       ‘-i’ 또는 ‘–in-interface’ :: packet을 수신할 interface를 명시합니다.       ‘-o’ 또는 ‘–out-interface’ :: packet이 전송될 interface를 명시합니다.       ‘-f’ 또는 ‘–fragment’ :: 조각난 packet의 두 번째와 그 이후 IPv4 조각만을 참조하는 rule을 명시합니다.       ‘-c’ 또는 ‘–set-counters’ :: INSERT, APPEND, REPLACE 조작 중에 rule의 packet 및 바이트 카운터(byte counters)를 초기화할 수 있습니다.           3.5. command     iptables이 수행할 작업을 지정합니다.   각각의 command에 대한 설명은 아래와 같습니다.            ‘-A’ 또는 ‘–append’ :: 선택한 chain 끝에 하나 이상의 rule을 추가합니다.       ‘-C’ 또는 ‘–check’ :: 선택한 chain의 rule과 일치하는 rule이 있는지 확인합니다.       ‘-D’ 또는 ‘–delete’ :: 선택한 chain에서 하나 이상의 rule을 삭제합니다.       ‘-I’ 또는 ‘–insert’ :: rule number로 선택한 chain에 하나 이상의 rule을 삽입합니다.       ‘-R’ 또는 ‘–replace’ :: rule number로 선택한 chain에서 rule을 교체합니다.       ‘-L’ 또는 ‘–list’ :: 선택한 chain의 모든 rule을 조회하며, chain을 선택하지 않으면 모든 chain의 rule을 조회합니다.       ‘-S’ 또는 ‘–list-rules’ :: 선택한 chain의 모든 rule을 출력하며, chain을 선택하지 않으면 모든 chain의 rule을 출력합니다.       ‘-F’ 또는 ‘–flush’ :: 선택한 chain의 rule을 모두 삭제합니다.       ‘-N’ 또는 ‘–new’ :: 사용자 정의 chain을 생성합니다.       ‘-E’ 또는 ‘–rename-chain’ :: 사용자 정의 chain의 이름을 변경합니다.       ‘-X’ 또는 ‘–delete-chain’ :: 사용자 정의 chain을 삭제합니다. 단, chain에 대한 참조(references)가 없고, rule이 없이 비어있어야 합니다.       ‘-P’ 또는 ‘–policy’ :: 사용자 정의 chain을 제외한 built-in chain의 policy를 지정한 target으로 설정합니다.       ‘-Z’ 또는 ‘–zero’ :: 모든 chain 또는 선택한 chain, chain의 지정된 rule의 packet과 byte counters를 0으로 설정합니다.           4. iptables 사용 방법  4.1. rule 추가     ‘-A’ 또는 ‘–append’ command를 사용합니다.   # iptables [table] -A chain rule-specification      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -A chain -m MATCH-NAME [match-options] -j TARGET-NAME [target-options]      예제 :: INPUT chain의 localhost 접속 허용 rule을 추가합니다.   # iptables -A INPUT -i lo -j ACCEPT   4.2. rule 확인     ‘-C’ 또는 ‘–check’ command를 사용합니다.   # iptables [table] -C chain rule-specification      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -C chain -m MATCH-NAME [match-options] -j TARGET-NAME [target-options]      예제 :: INPUT chain의 tcp 8080 포트(이하 port) 접속 허용 rule을 확인합니다.   # iptables -C INPUT -p tcp --dport 8080 -j ACCEPT   4.3. rule 삭제     ‘-D’ 또는 ‘–delete’ command를 사용합니다.   # iptables [table] -D chain rule-specification      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -D chain -m MATCH-NAME [match-options] -j TARGET-NAME [target-options]      예제 :: INPUT chain의 tcp 22 port 접속 차단 rule을 삭제합니다.   # iptables -D INPUT -p tcp -m tcp --dport 22 -j REJECT   4.4. rule number로 rule 삭제     ‘-D’ 또는 ‘–delete’ command를 사용합니다.   # iptables [table] -D chain rule-number      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -D chain rule-number      예제 :: FORWARD chain의 rule number 1번 rule을 삭제합니다.   # iptables -D FORWARD 1   4.5. rule 삽입     ‘-I’ 또는 ‘–insert’ command를 사용합니다.   # iptables [table] -I [rule-number] rule-specification      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -I chain [rule-number] -m MATCH-NAME [match-options] -j TARGET-NAME [target-options]      예제 :: INPUT chain의 rule number 1번에 udp 53 port 접속 차단 rule을 삽입합니다.   # iptables -I INPUT 1 -p udp --dport 53 -j DROP   4.6. rule 교체     ‘-R’ 또는 ‘–replace’ command를 사용합니다.   # iptables [table] -R rule-number rule-specification      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -R chain rule-number -m MATCH-NAME [match-options] -j TARGET-NAME [target-options]      예제 :: INPUT chain의 rule number 1번에 출발지 network ‘10.0.1.0/24’ 대역의 tcp 8080 port 접속 허용 rule을 교체합니다.   # iptables -R INPUT 1 -p tcp -s 10.0.1.0/24 --dport 8080 -j ACCEPT   4.7. rule 조회     ‘-L’ 또는 ‘–list’ command를 사용합니다.   # iptables [table] -L [chain [rule-number]] [options]      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -L [chain [rule-number]] [options]      예제 :: 모든 rule을 service 이름으로 조회합니다.   # iptables -L      예제 :: 모든 rule을 port number로 조회합니다.   # iptables -L -n   4.8. rule 모두 삭제     ‘-F’ 또는 ‘–flush’ command를 사용합니다.   # iptables [table] -F [chain [rule-number]] [options]      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -F [chain [rule-number]] [options]      예제 :: 모든 chain의 rule을 삭제합니다.   # iptables -F      예제 :: FORWARD chain의 모든 rule을 삭제합니다.   # iptables -F FORWARD   4.9. rule 출력     ‘-S’ 또는 ‘–list-rules’ command를 사용합니다.   # iptables [table] -S [chain [rule-number]]      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -S [chain [rule-number]]      예제 :: OUTPUT chain의 rule number 1번 rule을 출력합니다.   # iptables -S OUTPUT 1   4.10. 사용자 정의 chain 생성     ‘-N’ 또는 ‘–new’ command를 사용합니다.   # iptables [table] -N chain      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -N chain      예제 :: ‘lindarex-chain-income’이라는 이름의 사용자 정의 chain을 생성합니다.   # iptables -N lindarex-chain-income   4.11. 사용자 정의 chain 이름 변경     ‘-E’ 또는 ‘–rename-chain’ command를 사용합니다.   # iptables [table] -E old-chain-name new-chain-name      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -E old-chain-name new-chain-name      예제 :: 생성한 ‘lindarex-chain-income’이라는 이름의 사용자 정의 chain의 이름을 ‘lindarex-chain-income-new’로 변경합니다.   # iptables -E lindarex-chain-income lindarex-chain-income-new   4.12. 사용자 정의 chain 삭제     ‘-X’ 또는 ‘–delete-chain’ command를 사용합니다.   # iptables [table] -X [chain]      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -X [chain]      예제 :: 생성한 ‘lindarex-chain-income-new’라는 이름의 사용자 정의 chain을 삭제합니다.   # iptables -X lindarex-chain-income-new   4.13. built-in chain의 policy target 설정     ‘-P’ 또는 ‘–policy’ command를 사용합니다.   # iptables [table] -P chain target      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -P chain -j TARGET-NAME [target-options]      예제 :: OUTPUT chain의 policy를 DROP으로 설정합니다.   # iptables -P FORWARD DROP   4.14. packet과 byte counters를 0으로 설정     ‘-Z’ 또는 ‘–zero’ command를 사용합니다.   # iptables [table] -Z [chain [rule-number]] [options]      상세히 설명하면 아래와 같습니다.   # iptables [-t TABLE-NAME] -Z [chain [rule-number]] [options]      예제 :: FORWARD chain의 모든 rule의 counters를 0으로 설정합니다.   # iptables -Z FORWARD   마무리(CONCLUSION)  Ubuntu 환경에 iptables 설정을 완료했습니다.   iptables 설정을 통해 서버 보안을 많이 향상할 수 있지만, 잘못 설정할 경우에는 접속을 못 하는 경우가 발생할 수 있으니 신중하게 설정해야 합니다.   다음 포스트에서는 Ubuntu Server 운영 시 유용한 패키지를 소개하겠습니다.   참고(REFERENCES)     https://ko.wikipedia.org/wiki/iptables   https://www.linuxtopia.org/index.html   https://fedoraproject.org/wiki/How_to_edit_iptables_rules   https://linux.die.net/man/8/iptables  ","categories": ["ubuntu"],
        "tags": ["iptables","ubuntu"],
        "url": "https://lindarex.github.io/ubuntu/ubuntu-iptables-setting/",
        "teaser":"https://lindarex.github.io/assets/images/LindaRex_LOGO.jpg"}]
